[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Amostragem e Inferência Estatística",
    "section": "",
    "text": "Apresentação\n\n\n\n\n\n\nNota\n\n\n\nAo apresentar data.frames como resultados das análises de dados, utilizaremos o pacote flextable para fins de apresentação gráfica. Caso deseje rodar os códigos no RStudio, remova as funções flextable() e outras funções associadas (ex.: fit_to_width(max_width = 8)).\nOs pacotes utilizados aparecem ao início de cada capítulo."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/01-popamostra.html#população-amostra-e-unidade-amostral",
    "href": "qmd/01-amostragem_delineamento/01-popamostra.html#população-amostra-e-unidade-amostral",
    "title": "1  Descrevendo populações e amostras",
    "section": "1.1 População, amostra e unidade amostral",
    "text": "1.1 População, amostra e unidade amostral\nUma população estatística são todos os elementos sobre os quais queremos tirar conclusões. Refere-se ao conjunto de medidas que podem ser mensuradas como resultado de um experimento. As medidas que compõem a população estatística podem ser pesos, temperaturas, velocidades, tempos de reação, entre outras, a depender das características de um estudo particular. Uma população estatística pode ser finita ou infinita. Quando é finita, o número de elementos é dado por \\(N\\). O termo população não pode ser confundido com seu uso do dia-a-dia, quando refere-se a conjuntos de pessoas ou de organismos, nem mesmo com os elementos físicos nos quais as variáveis foram mensuradas.\nA abrangência da população estatística depende do contexto e do escopo da pergunta que se pretende responder.\n\nExemplo 1: Suponha um estudo para descrever o comprimento do lambari Deuterodon iguape em riachos do litoral de São Paulo. A população estatística não são os peixes em si, mas o comprimento de cada indivíduo que habita os riachos destas bacias. Dado o escopo do estudo (bacias do litoral de São Paulo), a população estatística abrange somente comprimentos dos organismos existem nesta região.\nExemplo 2: Suponha agora que desejamos estudar a diversidade de espécies de peixes em bacias costeiras do litoral de São Paulo. Neste caso, a população estatística seria constituida de um índice de diversidade calculado para cada uma das bacias costeiras do litoral. Fica claro que, neste caso, população estatística não se refere a população biológica, mas sim a variável que foi mensurada a partir do conjunto de espécies que habitam cada bacia.\n\nNestes dois exemplos é inviável obter informações de todos os elementos que compõem a população estaística. No caso dos comprimentos, não temos como capturar todos os animais presentes em uma bacia hidrográfica, mas ainda que tivéssemos seria inviável medir todos, pois existem provavelmente alguns milhares de peixes somente em um pequeno trecho de riacho. Já o número de Bacias costeiras no litoral do Estado de São Paulo é bem menor, porém ainda seria inviável mensurar a diversidade de espécies em todas elas.\nUm censo ocorre nos raros exemplos em que é possível mensurar todos os elementos da população estatística. Entretanto, a prática científica lida com a maioria dos casos em que mensuramos um subconjunto da população estatística, definido como uma amostra. O tamanho da amostra é denominado de \\(n\\).\nFinalmente, unidade amostral é definida como um único elemento da população estatística. A unidade amostral é uma determinada observação da variável de interesse. No exemplo dos lambaris, unidade amostral é o comprimento mensurado em um indivíduo da espécie de interesse, enquanto no exemplo das bacias costeiras, as unidades amostrais são cada um dos valores de diversidade calculados para cada bacia costeira.\n\n\n\n\n\n\nDEFINIÇÕES\n\n\n\nPopulação estatística: todos os elementos que podem compor uma amostra. Podem ser medidas como comprimentos, temperaturas, velocidades, etc.\nUnidade amostral: um único elemento da população.\nCenso: o levantamento de todos os elementos da população.\nAmostra: um subconjunto extraído da população.\nTamanho populacional (N): o número de elementos da população.\nTamanho amostral (n): o número de elementos da amostra."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/01-popamostra.html#distribuição-de-frequências-na-população-estatística",
    "href": "qmd/01-amostragem_delineamento/01-popamostra.html#distribuição-de-frequências-na-população-estatística",
    "title": "1  Descrevendo populações e amostras",
    "section": "1.2 Distribuição de frequências na população estatística",
    "text": "1.2 Distribuição de frequências na população estatística\nOs valores em uma população estatística não são idênticos, de modo que poderíamos descrevê-los por meio de uma distribuição de frequência, em que algumas faixas de valores são mais frequentes que outras. Os comprimentos de Deuterodon iguape por exemplo devem variar de alguns milímetros (pós-larva) a cerca de 20 cm (adulto), em que nem todos os comprimentos são igualmente representados. Certamente, existem mais lambaris pequenos e médios do que lambaris grandes. De fato, animais muito grandes são os mais raros, de modo que se tivéssemos informação da população estatística, veríamos que faixas de valores muito elevados se tornariam cada vez menos frequentes.\n\n\n\nSe fosse possível observar todos os elementos da população estatística, saberíamos exatamente qual o formato de sua distribuição de frequências. Suponha por exemplo, a altura de adultos acima de 18 anos. Seria razoável supor que a maioria das alturas consiste de valores intermediários ao redor de, por exemplo, 170 centímetros. É razoável supor também que a frequência de pessoas muito altas ou muito baixas vai diminuindo gradativamente, de modo que é muito raro encontrarmos adultos muito altos (ex. acima de \\(200\\) centímetros) ou muito baixos (ex. menores que \\(150\\) centímetros). A figura abaixo, descreve uma distribuição de frequência de uma população fictícia de exatamente \\(N = 1000\\) alturas.\n\n\nCode\nmu = 170\nsd = 10\nN = 1000\nset.seed(1)\nadultos = data.frame(\n  CP = round(rnorm(n = N, mean = mu, sd = sd),2)\n  )\n\nplt_pop = ggplot(adultos, aes(x = CP)) +\n  geom_histogram(fill = 'dodgerblue4', \n                 color = 'black', bins = 20) +\n   labs(x = \"Alturas em centímetros\",\n        y = \"Frequência\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 10)) +\n  scale_y_continuous(breaks = seq(0, 200, by = 20)) +\n  coord_cartesian(ylim = c(0, 200), xlim = c(130, 220)) +\n  theme_classic(base_size = 15)\n\n\n\n\nCode\nplt_pop +\n  annotate(geom = 'text', x = 130, y = 175, \n           label = deparse(bquote('N' == .(N))), parse = TRUE, hjust = 0, size = 7) +\n  annotate(geom = 'text', x = 130, y = 155, \n           label = deparse(bquote(mu == .(mu) ~ 'm')), parse = TRUE, hjust = 0, size = 7)\n\n\n\n\n\nFigura 1.1: Distribuição de uma população estatística representando as alturas (em centímetros) de adultos acima de 18 anos.\n\n\n\n\nVemos que existem mais valores entre \\(160\\) e \\(180\\) e poucas observações extremas. Por exemplo, das \\(1000\\) observações, apenas 27 mais extremas que \\(190\\) cm, o que é condizente com nossa expectativa para a distribuição de frequências das alturas de indivíduos adultos."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/01-popamostra.html#distribuição-de-probabilidade-da-população-estatística",
    "href": "qmd/01-amostragem_delineamento/01-popamostra.html#distribuição-de-probabilidade-da-população-estatística",
    "title": "1  Descrevendo populações e amostras",
    "section": "1.3 Distribuição de probabilidade da população estatística",
    "text": "1.3 Distribuição de probabilidade da população estatística\nNa prática, como não temos acesso a toda a população estatística, não temos como visualizar toda a sua distribuição de frequência. Dizemos portanto, que conhecemos a população estatística quando conhecemos a função de probabilidades associada a variável que está sendo mensurada. No exemplo da Figura 1.1, diríamos que a variável altura segue uma distribuição normal de probabilidades. Quando descrevemos uma distribuição de probabilidades, precisamos caracterizá-la por meio de certas quantidades, ou parâmetros da distribuição. Na distribuição normal, os parâmetros de interesse são a média \\(\\mu\\) e o desvio padrão \\(\\sigma\\). No exemplo das alturas, \\(\\mu = 170\\) e \\(\\sigma = 10\\)."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/01-popamostra.html#distribuições-de-frequências-na-amostra",
    "href": "qmd/01-amostragem_delineamento/01-popamostra.html#distribuições-de-frequências-na-amostra",
    "title": "1  Descrevendo populações e amostras",
    "section": "1.4 Distribuições de frequências na amostra",
    "text": "1.4 Distribuições de frequências na amostra\n\n\nCode\nn = 50\nset.seed(2)\nselecao = sample(N, size = n)\nAm1 = sort(adultos$CP[selecao], decreasing = FALSE)\n\n\nAinda que não tenhamos acesso a toda população estatística, gostaríamos de ter informações sobre a variável de interesse. Utilizamos o processo de amostragem para obter estas informações.\nSuponha, uma amostra de \\(n = 50\\) adultos. Se organizarmos esta amostra em valores crescentes teríamos:\n140.03, 151.5, 152.13, 152.91, 154.07, 158.14, 158.32, 159.59, 159.69, 160.14, 160.42, 160.46, 161.48, 161.89, 162.05, 163.11, 163.59, 163.77, 165.36, 166.11, 166.38, 166.69, 166.76, 167.03, 168.55, 169.72, 170.56, 172.17, 172.94, 173.8, 173.92, 174.34, 174.5, 175.24, 175.76, 175.95, 176.16, 177.13, 177.63, 177.66, 178.03, 178.48, 180.96, 180.97, 183.94, 184.17, 187.54, 187.64, 188.87, 191.69\nOs valores estão entre \\(140.03\\) e \\(191.69\\), o que certamente não é igual aos valores máximos e mínimos da população. Vamos representar esta amostra por meio de um histograma.\n\n\nCode\namostra_df = data.frame(CP = adultos$CP[selecao]) \nggplot(amostra_df, aes(x = CP)) +\n  geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 15) +\n   labs(x = \"Alturas em centímetros\",\n        y = \"Frequência\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 10)) +\n  scale_y_continuous(breaks = seq(0, 10, by = 1)) +\n  coord_cartesian(xlim = c(130, 220), ylim = c(0, 10)) +\n  theme_classic(base_size = 15)\n\n\n\n\n\nFigura 1.2: Amostra de tamanho n = 50 da população estatística de alturas.\n\n\n\n\nAinda que a distribuição da amostra não seja igual à da população estatística, podemos perceber que há uma concentração de valores justamente entre \\(160\\) cm e \\(180\\) cm, assim como na população estatística.\nA diferença entre a distribuição da população e a distribuição da amostra é esperada e ocorre porque estamos observando um subconjunto particular de elementos. Deste modo, sempre que amostrarmos uma população estatística, teremos uma amostra ligeiramente diferente.\nVamos verificar por exemplo, as distribuições de frequência de seis amostras possíves de tamanho \\(n = 50\\) desta mesma população.\n\n\nCode\nplot_list = list()\nfor (i in 1:6){\n  df = slice_sample(adultos, n = n)\n  p = ggplot(df, aes(x = CP)) +\n    geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n    labs(x = \"Alturas em centímetros\",\n         y = \"Frequência\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 20)) +\n  scale_y_continuous(breaks = seq(0, 16, by = 2)) +\n  coord_cartesian(xlim = c(130, 220), ylim = c(0, 16)) +\n    theme_classic()\n  plot_list[[i]] = p\n}\n\n(plot_list[[1]] + plot_list[[2]] + plot_list[[3]]) /\n  (plot_list[[4]] + plot_list[[5]] + plot_list[[6]])\n\n\n\n\n\nFigura 1.3: Seis diferentes amostra de tamanho n = 50 da população estatística de alturas.\n\n\n\n\nCada amostra resulta em distribuições diferentes, mas em todas a frequência de observações na faixa intermediária é maior. O processo de amostragem nos forneceu portanto amostras representativas da população estatística, isto é, amostras em que a distribuição de frequências se aproximou da distribuição de frequências da população.\nNeste exemplo fictício, como conhecemos a população estatística é fácil verificar que as amostras foram representativas. Na prática científica não conhecemos a população estatística e, consequentemente, não temos como saber se a nossa amostra em particular foi ou não representativa.\nDevemos portanto conduzir o processo de tal forma que a teoria da amostragem nos garanta que a amostra resultante de um determinado experimento seja, em média, representativa da população. O modo mais simples de garantir este comportamento é realizarmos uma amostra aleatória dos elementos da população estatística."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/01-popamostra.html#parâmetros-e-estimadores",
    "href": "qmd/01-amostragem_delineamento/01-popamostra.html#parâmetros-e-estimadores",
    "title": "1  Descrevendo populações e amostras",
    "section": "1.5 Parâmetros e estimadores",
    "text": "1.5 Parâmetros e estimadores\nA população estatística tem determinadas quantias de interesse que definimos como parâmetros da população. Se fosse possível medir as alturas dos \\(N = 1000\\) adultos, poderíamos calcular a média da população. Seja uma variável \\(X\\) composta por \\(X_1, X_2, X_3, \\cdots , X_N,\\), a média da população estatística é denominada de \\(\\mu\\) e definida por:\n\\[\\mu=\\frac{X_1+X_2+X_3+\\cdots+X_N}{N}=\\frac{\\sum_{i=1}^N{X_i}}{N}\\] Como não temos acesso a toda a população não podemos obter \\(\\mu\\), mas podemos estimá-lo por meio de uma amostra. Neste caso, seja uma amostra de tamanho \\(n\\) composta por \\(X_1, X_2, X_3, \\cdots, X_n\\), a média da amosta é denominada de \\(\\overline{X}\\) e definida por:\n\\[\\overline{X}=\\frac{X_1+X_2+X_3+\\cdots+X_n}{n}=\\frac{\\sum_{i=1}^n{X_i}}{n}\\]\nDizemos que \\(\\overline{X}\\) é um estimador não viciado de \\(\\mu\\).\nComo os valores da população estatística não são idênticos, podemos obter uma medida de dispersão como a variância populacional (\\(\\sigma^2\\)) definida por:\n\\[\\sigma^2=\\frac{\\sum_{i=1}^N{(X_i - \\mu)^2}}{N}\\]\nNovamente, como não temos acesso a todos os \\(N\\) elementos, podemos apenas calcular a variância amostral (\\(s^2\\)) definida por:\n\\[s^2=\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}\\]\nNote que na expressão acima, substituimos \\(\\mu\\) por \\(\\overline{X}\\) pois estamos nos referindo à variância da amostra. No denominador fizemos a divisão por \\(n-1\\) não por \\(N\\). Estas mudanças são necessárias para que \\(s^2\\) seja um estimador não-viciado de \\(\\sigma^2\\).\nDenominamos de parâmetro ao descritor obtido a partir da mensuração de todos os elementos da população estatística e de estimador (ou estatística), a quantia obtida a partir da amostra. Os parâmetros são comumente representados por letras gregas. O símbolo \\(\\mu\\) e \\(\\sigma^2\\) representam, respectivamente, a média e variância populacionais, enquanto \\(\\overline{X}\\) e \\(s^2\\) são a média e variância amostrais.\n\n\n\n\n\n\nDEFINIÇÕES\n\n\n\nParâmetro: a medida que descreve uma característica da população estatística. Ex.: a média (\\(\\mu\\)) ou a variância (\\(\\sigma^2\\)) populacional.\nEstimador ou Estatística: Uma medida que descreve uma característica da amostra. Ex.: a média amostral (\\(\\overline{X}\\)) ou a variância amostral (\\(s^2\\)). Os estimadores támbem podem ser representados por letras gregas com o símbolo \\(\\hat{}\\). A variância amostral, por exemplo, pode ser representada por \\(\\hat{\\sigma}^2\\).\nEstimativa: é o valor numérico assumido pelo estimador. Ex. o valor numérico calculado para a média ou variância de uma amostra em particular.\n\n\n\n1.5.1 Verificando as propriedades de \\(\\overline{X}\\) e \\(s^2\\)\n\n\nCode\nNsmall = 5\nnsmall = 2\nset.seed(5)\npop_small = sample(20, size = Nsmall, replace = F)\nmu = mean(pop_small)\nsigma2 = sum((pop_small - mu)^2)/Nsmall\n\nm = matrix(NA, ncol = Nsmall, nrow = Nsmall)\nrownames(m) = colnames(m) = as.character(pop_small)\nfor (i in 1:Nsmall){\n  for (j in 1:Nsmall){\n    m[i,j] = paste('(', pop_small[i], ' ; ', pop_small[j], ')', sep = '')\n  }\n}\n\n\nPor meio de um exmplo, vamos verificar empiricamente que \\(\\overline{X}\\) e \\(s^2\\) são estimadores não viciados de \\(\\mu\\) e \\(\\sigma^2\\) respectivamente. Suponha uma população de somente \\(5\\) elementos.\n\\[2 - 11 - 15 - 19 - 9\\]\n1. Calculando \\(\\mu\\) e \\(\\sigma^2\\).\nComo conhecemos a população vamos obter:\n\\[\\mu = \\frac{\\sum_{i=1}^N{X_i}}{N} = \\frac{2 + 11 + 15 + 19 + 9}{5}= \\frac{5}{5} = 11.2\\]\ne\n\\[\\sigma^2=\\frac{\\sum_{i=1}^N{(X_i - \\mu)^2}}{N} = \\frac{164.8}{5} = 32.96\\]\n2. Amostrando a população estatística\nA Tabela 1.1 mostra todas as \\(25\\) amostras com reposição de tamanho \\(n = 2\\) que podem ser obtidas desta população.\nA tabela abaixo mostra todas as \\(25\\) amostras com reposição de tamanho \\(n = 2\\) que podem ser obtidas desta população.\n\n\nCode\nknitr::kable(m)\n\n\n\n\nTabela 1.1: Todas as amostras possíveis de tamanho n = 2 da população estatística com N = 5\n\n\n\n2\n11\n15\n19\n9\n\n\n\n\n2\n(2 ; 2)\n(2 ; 11)\n(2 ; 15)\n(2 ; 19)\n(2 ; 9)\n\n\n11\n(11 ; 2)\n(11 ; 11)\n(11 ; 15)\n(11 ; 19)\n(11 ; 9)\n\n\n15\n(15 ; 2)\n(15 ; 11)\n(15 ; 15)\n(15 ; 19)\n(15 ; 9)\n\n\n19\n(19 ; 2)\n(19 ; 11)\n(19 ; 15)\n(19 ; 19)\n(19 ; 9)\n\n\n9\n(9 ; 2)\n(9 ; 11)\n(9 ; 15)\n(9 ; 19)\n(9 ; 9)\n\n\n\n\n\n\n3. Calculando \\(\\overline{X}\\) e \\(s^2\\).\nEm seguida, organizamos as amostras em uma outra tabela, de modo que possamos calcular, para cada uma, os estimadores \\(\\overline{X}\\) e \\(s^2\\)\n\n\nCode\ntab_df = data.frame(expand_grid(pop_small, pop_small))\ncolnames(tab_df) = c('X1', 'X2')\ntab_df = tab_df %>% \n  rowwise() %>% \n  mutate(Xm = mean(c(X1,X2)),\n         s2 = var(c(X1,X2)))\nEx = mean(tab_df$Xm)\nEs2 = mean(tab_df$s2)\n\n\n\n\nCode\ntab_df %>% \n  knitr::kable(col.names = c('$x_1$', '$x_2$', '$\\\\overline{X}$', '$s^2$'))\n\n\n\n\nTabela 1.2: Média e variância amostrais para todas as amostras possíveis de tamanho n = 2 da população estatística com N = 5\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(\\overline{X}\\)\n\\(s^2\\)\n\n\n\n\n2\n2\n2.0\n0.0\n\n\n2\n11\n6.5\n40.5\n\n\n2\n15\n8.5\n84.5\n\n\n2\n19\n10.5\n144.5\n\n\n2\n9\n5.5\n24.5\n\n\n11\n2\n6.5\n40.5\n\n\n11\n11\n11.0\n0.0\n\n\n11\n15\n13.0\n8.0\n\n\n11\n19\n15.0\n32.0\n\n\n11\n9\n10.0\n2.0\n\n\n15\n2\n8.5\n84.5\n\n\n15\n11\n13.0\n8.0\n\n\n15\n15\n15.0\n0.0\n\n\n15\n19\n17.0\n8.0\n\n\n15\n9\n12.0\n18.0\n\n\n19\n2\n10.5\n144.5\n\n\n19\n11\n15.0\n32.0\n\n\n19\n15\n17.0\n8.0\n\n\n19\n19\n19.0\n0.0\n\n\n19\n9\n14.0\n50.0\n\n\n9\n2\n5.5\n24.5\n\n\n9\n11\n10.0\n2.0\n\n\n9\n15\n12.0\n18.0\n\n\n9\n19\n14.0\n50.0\n\n\n9\n9\n9.0\n0.0\n\n\n\n\n\n\nVemos que a média amostral pode variar entre 2, quando amostramos o menor valor da população duas vezes (isto é, o número 2) e 19, quando a amostra contém o maior valor da população (isto é, 19). Vemos ainda que existe uma maior concentração de valores entre \\(8\\) e \\(14\\) e que a distribuição das médias é aproximadamente simétrica.\nPara a variância amostral \\(s^2\\) também verificamos uma grande diferença entre as amostras particulares, com resultados que varia entre 0 e 144.5, além de uma distribuição altamente assimétrica.\n\n\nCode\nplt_Xm = ggplot(tab_df, aes(x = Xm)) +\n  geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n   labs(x = bquote('Distribuição de ' ~ bar(X)),\n        y = \"Frequência\") +\n  scale_x_continuous(breaks = seq(0, 20, by = 2)) +\n  theme_classic(base_size = 15)\n\nplt_s2 = ggplot(tab_df, aes(x = s2)) +\n  geom_histogram(fill = 'red4', color = 'black', bins = 12) +\n   labs(x = bquote('Distribuição de ' ~ s^2),\n        y = \"Frequência\") +\n  scale_x_continuous(breaks = seq(0, 200, by = 20)) +\n  theme_classic(base_size = 15)\n\n\n\n\nCode\nplt_Xm | plt_s2\n\n\n\n\n\nFigura 1.4: Distribuição das médias e variâncias amostrais com n = 2\n\n\n\n\n3. Verificando os valores esperados de \\(\\overline{X}\\) e \\(s^2\\).\nPara verificar empiricamente os valores esperados de \\(\\overline{X}\\) e \\(s^2\\) podemos encontrar sua médias. Vemos que:\n\\[\\overline{\\overline{X}} = \\frac{\\sum_{i=1}^{25}{280}}{25} = 11.2 = \\mu\\]\ne que\n\\[\\overline{s^2} = \\frac{\\sum_{i=1}^{25}{824}}{25} = 32.96 = \\sigma^2\\]\nEstes resultados mostram que, em média, espera-se que as estimativas de \\(\\overline{X}\\) e \\(s^2\\) coincidem exatamente com os parâmetros \\(\\mu\\) e \\(\\sigma^2\\). Quando isto ocorre dizemos que o estimador é não viciado.\n\n\n\n\n\n\nAmostragem com e sem reposição\n\n\n\nA discussão acima é válida para a amostragem de uma população infinita ou para a amostragem com reposição de uma população finita de tamanho \\(N\\). Se a amostragem for feita sem reposição de uma população finita, \\(\\overline{X}\\) continua sendo o estimador não viciado de \\(\\mu\\), porém o estimador não viciado da variância fica:\n\\(s^2 = \\left( \\frac{N-1}{N} \\right) \\left( \\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1} \\right)\\)\nNa prática, raramente conduzimos uma amostragem com reposição. No entanto, ou a população é infinita como nos casos de estudos experimentais, ou a população é finita porém muito grande, como na maioria dos estudos observacionais. Neste segundo caso, para populações finitas com \\(N\\) grande, o termo \\(\\left( \\frac{N-1}{N} \\right)\\sim 1\\)."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/01-popamostra.html#amostragem-e-inferência",
    "href": "qmd/01-amostragem_delineamento/01-popamostra.html#amostragem-e-inferência",
    "title": "1  Descrevendo populações e amostras",
    "section": "1.6 Amostragem e inferência",
    "text": "1.6 Amostragem e inferência\nO problema central que começamos e discutir neste capítulo e com o qual iremos lidar em estatística é que:\n\nEstamos interessados nas características da população estatística, porém só temos informação sobre a amostra.\nA estimativa obtida a partir de uma amostra particular é sujeita à variação decorrente do processo de amostragem.\n\nConsidere por exemplo, as diferentes amostras que podem ser obtidas a partir da população estatística de alturas para um \\(n = 50\\) amostras:\n\n\nCode\nplot_list = list()\nfor (i in 1:6){\n  df = slice_sample(adultos, n = n)\n  x_bar = mean(df$CP)\n  s2_bar = var(df$CP)\n  p = ggplot(df, aes(x = CP)) +\n    geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n    labs(x = \"Alturas em centímetros\",\n         y = \"Frequência\") +\n    scale_x_continuous(breaks = seq(130, 220, by = 20)) +\n    scale_y_continuous(breaks = seq(0, 16, by = 2)) +\n    coord_cartesian(xlim = c(130, 220), ylim = c(0, 16)) +\n    annotate(geom = 'text', x = 130, y = 15, label = deparse(bquote('n' == .(n))), parse = TRUE, hjust = 0, size = 3) +\n    annotate(geom = 'text', x = 130, y = 14, label = deparse(bquote(bar(X) == .(round(x_bar,2)))), parse = TRUE, hjust = 0, size = 3) +\n    annotate(geom = 'text', x = 130, y = 13, label = deparse(bquote(s^2 == .(round(s2_bar,2)))), parse = TRUE, hjust = 0, size = 3) +\n    theme_classic()\n  plot_list[[i]] = p\n}\n\n(plot_list[[1]] + plot_list[[2]] + plot_list[[3]]) /\n  (plot_list[[4]] + plot_list[[5]] + plot_list[[6]])\n\n\n\n\n\nFigura 1.5: Seis diferentes amostras de tamanho n = 50 da população de alturas.\n\n\n\n\nVemos que a cada nova amostra, \\(\\overline{X}\\) e \\(s^2\\) são numericamente diferentes e não coicidem com os parâmetros da população estatística (\\(\\mu = 11.2\\), \\(\\sigma^2 = 100\\)). Vemos entretanto, que mesmo sendo diferentes, estão ao redor dos parâmetros populacionais. Se pudermos conhecer algumas propriedades destes estimadores, seremos capazes de estabelecer limites de confiança sobre as conclusões que podemos tirar as respeito da população estatística.\nNeste sentido, o processo de amostragem e inferência consiste em:\n\nObter uma amostra representativa da população estatística;\nCalcular estimativas a partir das características da amostra (ex. \\(\\overline{X}\\) e \\(s^2\\));\nAssumir distribuições de probabilidade apropriadas para os estimadores;\nUtilizar para estas distribuições para calcular intervalos de confiança ou testar hipóteses estatísticas.\n\nEste processo pode ser resumido na figura abaixo e será discutido nos próximos capítulos.\n\n\n\n\n\n\nFigura 1.6: Processo de amostragem e inferência estatística.\n\n\n\n\n\n\n\n\n\nVídeo-aulas"
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/02-amostragem.html#amostragem-aleatória-simples",
    "href": "qmd/01-amostragem_delineamento/02-amostragem.html#amostragem-aleatória-simples",
    "title": "2  Amostrando uma População Estatística",
    "section": "2.1 Amostragem aleatória simples",
    "text": "2.1 Amostragem aleatória simples\nÉ aquela em que cada elemento da população tem a mesma probabilidade de ser selecionado para compor a amostra. Se a população consiste de \\(1000\\) elementos, cada um terá uma probabilidade de \\(\\frac{1}{1000}\\) de ser escolhido. Isto isenta o pesquisador de tomar qualquer decisão com base em julgamentos pré-concebidos, sobre quais elementos devem ou não compor a amostra.\n\n\nCode\nset.seed(1)\npop = c(3, 10, 14, 19, 27, 28, 29, 41, 42, 43)\nN = length(pop)\nAm1 = sort(pop)[1:5]\nset.seed(2)\nAm2 = sample(pop, size = 5, replace = F)\n\n\nSuponha uma população hipotética de somente \\(10\\) elementos:\nPopulação: 3, 10, 14, 19, 27, 28, 29, 41, 42, 43\nEm uma amostra aleatória simples de cinco elementos, qualquer combinação destes \\(10\\) elementos é igualmente provável. Se por puro acaso sortearmos uma amostra aleatória contendo os cinco menores valores da população:\nAmostra 1: 3, 10, 14, 19, 27\nA amostra seria tão aleatória e válida do ponto de vista estatístico quanto qualquer outra como:\nAmostra 2: 27, 28, 42, 3, 43\nIsto significa que uma amostra aleatória pode não ser necessariamente representativa da população. Amostras pequenas por exemplo, têm uma chance maior de selecionar apenas valores extremos, ou seja, os maiores ou menores elementos da população. A média amostral (\\(\\overline{X}\\)) calculada para estas amostras estará distante da média populacional (\\(\\mu\\)). No entanto, a importância central da amostragem aleatória em estatística está no fato de que a aleatoriedade produz, em média, amostras representativas da população. Deste modo, é esperado que na maioria das vezes, uma amostra aleatória gere médias amostrais próximas à média populacional. Por este motivo, é fundamental prezar pela aleatoriedade no processo amostral, pois de outro modo não poderemos garantir que a inferência seja válida com base nas leis de probabilidade.\nO modo mais direto de se obter uma amostra aleatória é por meio de sorteio. Após atribuir números de 1 a \\(N\\) a cada unidade amostral, estas unidades são sorteadas até que seja atingido o tamanho \\(n\\) desejado. Na prática, nem sempre é simples, ou mesmo possível obter uma amostra aleatória nestes moldes. Não seria possível enumerar todos os peixes de uma região para, após um sorteio, tomar as medidas somente dequeles selecionados. Entretanto, se empregarmos métodos de captura em que indivíduos de todos os tamanhos sejam igualmente sujeitos a serem capturados poderíamos no aproximar do que seria uma amostra verdsadeiramente aleatória. Outras dificuldades práticas surgiriam neste estudo como por exemplo: garantir acesso irrestrito à toda a área de ocorrência da espécie, tempo disponível para percorrer a toda região. Questões como estas não desmerecem o requisito básico de se obter uma amostra aleatória, mas devem nos auxiliar a decidir como conciliar a prática experimental com a necessidade de garantirmos uma amostra aleatória."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/02-amostragem.html#amostragem-aleatória-estratificada",
    "href": "qmd/01-amostragem_delineamento/02-amostragem.html#amostragem-aleatória-estratificada",
    "title": "2  Amostrando uma População Estatística",
    "section": "2.2 Amostragem aleatória estratificada",
    "text": "2.2 Amostragem aleatória estratificada\nSe tivermos algum conhecimento prévio de como a população está estruturada, a amostra aleatória simples, embora não esteja incorreta, pode não ser a estratégia mais eficiente do ponto de vista estatístico. Se for possivel identificar estratos ou subgrupos dentro da população, podemos conduzir uma amostragem aleatória estatificada.\nVoltemos ao exemplo do comprimento do pescado. Suponha que existam duas áreas de ocorrência da espécie. Uma delas sujeita a intensa atividade pesqueira e outra sendo uma área protegida. Poderíamos supor que na área protegida estejam os maiores indivíduos, justamente porque nesta área não há atividade de pesca (que em geral busca indivíduos maiores). Dizemos que os comprimentos em cada uma das duas regiões compõem estratos da população estatística.\nNesta situação, uma amostra puramente aleatória sem considerar a existência dos dois estratos pode fazer com que, puramente ao acaso, um deles se torne mais representados na amostra. Se por exemplo da maioria dos pontos selecionados estiverem na região intensamente pescada, o comprimento médio da amostra (\\(\\overline{X}\\)) tenderá a ficar consistentemente abaixo de \\(\\mu\\). A chance disto ocorrer se torna maior principalmente se o tamanho amostral for pequeno.\nEntretanto, se a seleção dos indivíduos foi feita por meio de sorteio, o simples fato de observarmos este padrão não seria por si só justificativa para refarzermos a amostra. O ponto relevante aqui é que em uma amostra aleatória simples, estes extremos indesejáveis (um estrato mais representado que outro) são mais prováveis de acontecer.\nSe temos conhecimento da existência dos dois estratos portanto, a amostragem aleatória estratificada seria a mais indicada. Neste tipo de amostragem, o esforço amostral é subdividido entre os estratos. O tamanho amostral em cada estrato será o mesmo, ou proporcional ao seu tamanho. Uma vez definirmos os tamanhos amostrais que será aplicado aos estratos, as unidades são selecionadas por meio de uma amostragem aleatória simples em cada um.\nA amostragem aleatória estratificada garante que todos os estratos estejam presentes na amostra conforme sua representatividade na população. Ao fazer isto, as estimativas da amostra tenderão a se concentrar mais próximas ao parâmetro da população. Deste modo, quando os estratos são identificados corretamente, a principal vantagem da amostra aleatória estratificada sobre a amostra aleatória simples está em aumentar a precisão das estimativas. Mais a frente iremos discutir os conceitos de precisão e acurácia e relacioná-los com as estratégias amostrais discutidas aqui."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/02-amostragem.html#amostragem-sistemática",
    "href": "qmd/01-amostragem_delineamento/02-amostragem.html#amostragem-sistemática",
    "title": "2  Amostrando uma População Estatística",
    "section": "2.3 Amostragem sistemática",
    "text": "2.3 Amostragem sistemática\nEm uma amostragem sistemática o pesquisador escolhe um elemento inicial e toma medidas a cada \\(k\\) ocorrências, seguindo a ordem de observação. No caso do comprimento de pescado, para facilitar a tomada de dados, o pesquisador pode medir o primeiro peixe coletado e, em seguida, medir os peixes em intervalos regulares, por exemplo a cada \\(10\\) observados.\nA escolha da amostragem sistemática ao invés de uma amostragem aleatória simples, deve-se à sua praticidade. Se a característica de interesse das unidades amostrais estiver disposta de forma aleatória ao longo da sequência escolhida, a amostragem aleatória e sistemática irão gerar resultados similares. Na maioria dos casos, é isto que o pesquisador assume (ainda que implicitamente) quando opta por uma amostragem sistemática."
  },
  {
    "objectID": "qmd/01-amostragem_delineamento/02-amostragem.html#erro-amostral-acurácia-e-precisão",
    "href": "qmd/01-amostragem_delineamento/02-amostragem.html#erro-amostral-acurácia-e-precisão",
    "title": "2  Amostrando uma População Estatística",
    "section": "2.4 Erro amostral, acurácia e precisão",
    "text": "2.4 Erro amostral, acurácia e precisão\nComo as estimativas são obtidas de um subconjunto da população (a amostra), é regra que o resultado obtido de uma amostra aleatória particular, não será igual ao verdadeiro valor da população (o parâmetro), embora exista uma grande probabilidade estar próximo.\n\nErro amostral: é a diferença entre uma estimativa em particular e o parâmetro na população e portanto, é inerente à variabilidade do processo de amostragem. Suponha que, puramente ao acaso, a amostra inclua os menores elementos da população. A média amostral (\\(\\overline{X}\\)) estará muito abaixo da média populacional (\\(\\mu\\)) e o erro amostral será grande. Se calcularmos a média (\\(\\overline{X}\\)) de uma amostra particular, o erro amostral será dado por:\n\n\\[E = \\overline{X} - \\mu\\]\nA estatística estuda o comportamento probabilístico dos erros amostrais. Existe também o erro não amostral que decorre de equívocos de amostragem, inexperiência do amostrador, falha de equipamentos, enganos no cômputo dos resultados, etc. A estatística não lida com este tipo de erro.\n\nAcurácia: se refere à proximidade entre o parâmetro e o estimador. Um estimador acurado é, em média, igual ao parâmetro populacional. Diferente do erro amostral, a acurácia não se refere a uma estimativa em particular, mas ao valor esperado do estimador, caso a amostragem fosse repetida um grande número de vezes. Um estimador não-acurado (viciado) resulta em valores consistentemente diferentes do parâmetro, podendo estar acima (viés positivo) ou abaixo (viés negativo) do valor populacional. A média aritmética amostral (\\(\\overline{X}\\)) é um estimador não-viciado da média populacional (\\(\\mu\\)) pois:\n\n\\[\\mu_{\\overline{X}} = \\mu\\]\n\nPrecisão: tem relação com a variabilidade do estimador. Estimadores que geram estimativas similares entre si são mais precisos. Porém, se as estimativas estiverem distantes de sua média, o estimador é dito pouco preciso. Exemplo: Para uma população normalmente distribuída, tanto a média aritmética quanto a mediana são estimadores acurados. Entretanto, a variância da mediana é maior que da média aritmética. Dizemos portanto, que a média aritmética é um estimador mais preciso que a mediana. A precisão de um estimador é medida pelo erro padrão da média.\n\n\\[\\sigma_{\\overline{X}} =\\frac{\\sigma}{\\sqrt{n}}\\]\nA figura abaixo é comnmente utilizada para representar os conceitos de precição e acurácia. O centro do alvo é o valor do parâmetro populacional e os pontos em preto são as estimativas. Estimadores acurados geram, em média, estimativas ao redor do parâmetro populacional (viés \\(= 0\\)). Estimadores não-acurados geram, em média, valores deslocados do parâmetro populacional (viés \\(\\ne 0\\)). Estimadores precisos resultam sempre em estimativas próximas entre si, enquanto estimadores não precisos resultam em estimativas distantes umas das outras.\n\n\n\nFigura 2.1: Representação dos conceitos de precisão e acurácia.\n\n\n\n2.4.1 Erro amostral\nVoltemos à nossa população fictícia com \\(N = 10\\) elementos:\nPopulação: 3, 10, 14, 19, 27, 28, 29, 41, 42, 43\nPara esta população em particular nós conhecemos a média populacional (\\(\\mu\\) = 25.6), de modo que será possível compará-la com as estimativas amostrais.\n\n\nCode\nset.seed(4)\nn = 5\nAm1 = sample(pop, size = n, replace = F)\nsomaAm1 = paste(Am1, collapse = \"+\")\nmp = round(mean(pop),1)\nmAm1 = round(mean(Am1),1)\nE1 = mAm1 - mp\n\n\nVamos tomar uma amostra aleatória de tamanho \\(n = 5\\):\nAmostra 1: \\(41, 14, 42, 29, 19\\)\nPara esta amostra, a média vale: \\(\\overline{X} =\\frac{41+14+42+29+19}{5} = 29\\).\nOs valores \\(\\mu = 25.6\\) e \\(\\overline{X} = 29\\) não são idênticos, pois a amostra contém somente alguns elementos da população. A diferença entre \\(\\mu\\) e \\(\\overline{X}\\) é o chamamos de erro amostral.\nNeste caso, o erro amostral é:\nErro amostral 1: \\(E_1 = 29 - 25.6 = 3.4\\)\nSe tomarmos outra amostra aleatória, teremos outro conjunto de unidades amostrais, e consequentemente, um \\(\\overline{X}\\) e um erro amostral diferentes. Por exemplo:\n\n\nCode\nset.seed(3)\nn = 5\nAm2 = sample(pop, size = n, replace = F)\nmAm2 = round(mean(Am2),1)\nE2 = mAm2 - mp\n\n\nAmostra 2: \\(27, 29, 19, 10, 14\\)\nMédia amostral 2: \\(\\overline{X_2} = 19.8\\)\nErro amostral 2: \\(E_2 = 19.8 - 25.6 = -5.8\\)\n\n\n2.4.2 Acurácia\n\n\nCode\nN = length(pop)\nn = 5\nCT = choose(N,n)\n\n\nAté agora, analisamos duas amostras diferentes da população. Porém, quantas amostras distintas seriam possíveis? Para uma amostragem sem reposição, a teoria combinatória nos diz que são possíveis:\n\\[{{10}\\choose{5}} = \\frac{10!}{(10-5)! \\times 5!} = 252\\]\nformas diferentes de combinarmos \\(N = 10\\) elementos em amostras de tamanho \\(n = 5\\).\n\n\nCode\nset.seed(8)\nR = 8\nA15 = replicate(n = R, sample(pop, size = n, replace = F))\ncolnames(A15) = paste(\"A\", 1:ncol(A15), sep = \"\")\nMedias = round(apply(A15, 2, mean),2)\n\n\nInicialmente vamos avaliar a questão com um número menor. Sejam por exemplo, 8 amostras tomadas aleatoriamente, gerando os resultados a seguir:\n\n\nCode\nA15   %>% \n  as.data.frame() %>% \n  add_column('Obs' = rep('', times = nrow(A15)),.before = 'A1') %>% \n  rbind(Obs = c('Médias', Medias)) %>%\n  flextable() %>% \n  bg(i = ~ Obs == 'Médias', bg = 'lightblue') %>% \n  width(width = 1.5)\n\n\n\n\nTabela 2.1:  Oito amostras de tamanho n = 5 da população estatística. ObsA1A2A3A4A5A6A7A8192910194229284329431441291042281028424341271042423282814424327432729328432719Médias28.62624.626.830.830.23031.8\n\n\n\nCada coluna desta matriz corresponde a uma possível amostra aleatória e suas respectivas médias.\nAlgumas amostras tiveram médias muito distantes de \\(\\mu\\), como: \\(\\overline{X_{A8}} = 31.8\\) ou \\(\\overline{X_{A3}} = 24.6\\). Esta variação é natural do processo amostral. Os métodos de amostragem e de inferência estatística tratam justamente de como interpretar e como lidar com esta variação. Para entender melhor este processo, vamos obter todas as 252 combinações possíveis de amostras com \\(n = 5\\) e, em seguida, extrair suas respectivas médias.\nOs resultados das 252 médias possíveis podem ser vistos a seguir ordenados da menor para a maior média possível:\n\n\nCode\nAllcomb = combn(x = pop, m = 5)\nM_Allcomb = apply(Allcomb,2,mean)\nM_Allcomb_round = round(M_Allcomb,1)\nknitr::kable(matrix(M_Allcomb_round,nc = 14, byrow = T))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.6\n14.8\n15.0\n17.4\n17.6\n17.8\n16.4\n16.6\n19.0\n19.2\n19.4\n16.8\n19.2\n19.4\n\n\n19.6\n19.4\n19.6\n19.8\n22.0\n22.2\n22.4\n17.4\n17.6\n20.0\n20.2\n20.4\n17.8\n20.2\n\n\n20.4\n20.6\n20.4\n20.6\n20.8\n23.0\n23.2\n23.4\n19.4\n21.8\n22.0\n22.2\n22.0\n22.2\n\n\n22.4\n24.6\n24.8\n25.0\n22.2\n22.4\n22.6\n24.8\n25.0\n25.2\n25.0\n25.2\n25.4\n27.8\n\n\n18.2\n18.4\n20.8\n21.0\n21.2\n18.6\n21.0\n21.2\n21.4\n21.2\n21.4\n21.6\n23.8\n24.0\n\n\n24.2\n20.2\n22.6\n22.8\n23.0\n22.8\n23.0\n23.2\n25.4\n25.6\n25.8\n23.0\n23.2\n23.4\n\n\n25.6\n25.8\n26.0\n25.8\n26.0\n26.2\n28.6\n21.2\n23.6\n23.8\n24.0\n23.8\n24.0\n24.2\n\n\n26.4\n26.6\n26.8\n24.0\n24.2\n24.4\n26.6\n26.8\n27.0\n26.8\n27.0\n27.2\n29.6\n25.6\n\n\n25.8\n26.0\n28.2\n28.4\n28.6\n28.4\n28.6\n28.8\n31.2\n28.6\n28.8\n29.0\n31.4\n31.6\n\n\n19.6\n19.8\n22.2\n22.4\n22.6\n20.0\n22.4\n22.6\n22.8\n22.6\n22.8\n23.0\n25.2\n25.4\n\n\n25.6\n21.6\n24.0\n24.2\n24.4\n24.2\n24.4\n24.6\n26.8\n27.0\n27.2\n24.4\n24.6\n24.8\n\n\n27.0\n27.2\n27.4\n27.2\n27.4\n27.6\n30.0\n22.6\n25.0\n25.2\n25.4\n25.2\n25.4\n25.6\n\n\n27.8\n28.0\n28.2\n25.4\n25.6\n25.8\n28.0\n28.2\n28.4\n28.2\n28.4\n28.6\n31.0\n27.0\n\n\n27.2\n27.4\n29.6\n29.8\n30.0\n29.8\n30.0\n30.2\n32.6\n30.0\n30.2\n30.4\n32.8\n33.0\n\n\n23.4\n25.8\n26.0\n26.2\n26.0\n26.2\n26.4\n28.6\n28.8\n29.0\n26.2\n26.4\n26.6\n28.8\n\n\n29.0\n29.2\n29.0\n29.2\n29.4\n31.8\n27.8\n28.0\n28.2\n30.4\n30.6\n30.8\n30.6\n30.8\n\n\n31.0\n33.4\n30.8\n31.0\n31.2\n33.6\n33.8\n28.8\n29.0\n29.2\n31.4\n31.6\n31.8\n31.6\n\n\n31.8\n32.0\n34.4\n31.8\n32.0\n32.2\n34.6\n34.8\n33.4\n33.6\n33.8\n36.2\n36.4\n36.6\n\n\n\n\n\nA menor e maior médias possíveis são 14.6 e 36.6 respectivamente. Estes valores são os mais distantes do parâmetro populacional (\\(\\mu = 25.6\\)) e ocorrem puramente ao acaso quanto são amostrados os 5 menores (3, 10, 14, 19, 27) ou os 5 maiores (43, 42, 41, 29, 28) elementos da população estatística. Estes casos extremos são raros. Em nosso exemplo, valores superiores a 33.8 ou inferiores a 17.4 são muito improváveis.\nPodemos avaliar graficamente a distribuição das médias amostrais através de um histograma. A grande maioria das médias amostrais concentra-se na porção intermediária do gráfico entre estes limites. Por exemplo, somente 3.2% das observações estão acima de 33.8. Da mesma forma, somente 3.2% das observações estão abaixo de 17.4\n\n\nCode\nM_Allcomb_df = data.frame(M = as.numeric(M_Allcomb))\n\ngp5 <- ggplot(M_Allcomb_df, aes(x = M)) +\n  geom_histogram(fill = 'brown3', color = 'black', bins = 10) +\n  scale_x_continuous(breaks = seq(0, 50, by = 5)) +\n  coord_cartesian(xlim = c(10, 40)) +\n  labs(x = \"Médias\",\n       y = \"Frequência\") +\n  theme_classic()\n\ngp5\n\n\n\n\n\nFigura 2.2: Histograma das 252 médias amostrais obtidas a partis de amostras de tamanho n = 5.\n\n\n\n\nSe calcularmos a média das médias (\\(\\mu_{\\overline{X}}\\)), ou seja, somarmos todos estes valores e dividirmos por 252, o resultado será 25.6, que é exatamente o valor da média populacional \\(\\mu\\). Isto têm uma implicação central em inferência estatística. Significa que a média amostral \\(\\overline{X}\\) é um estimador acurado (= não-viciado), pois tende a estimar corretamente o valor da média populacional \\(\\mu\\). Ou seja, o histograma acima está centrado ao redor de \\(\\mu\\), o que significa que em média uma amostra particular tem maior probabilidade de expressar um \\(\\overline{X}\\) próximo ao valor populacional.\n\n\n2.4.3 Precisão: o erro padrão da média (\\(\\sigma_{\\overline{X}}\\))\n\n\nCode\nn2 = 7\nAllcomb7 = combn(x = pop, m = n2)\nM_Allcomb7 = apply(Allcomb7,2,mean)\nM_Allcomb7_round = round(M_Allcomb7,1)\nCT2 = choose(N,n2)\n\n\nSuponha agora que tomemos ao acaso amostras com \\(n = 7\\) desta mesma população. Existem ao todo:\n\\[{{10}\\choose{7}} = \\frac{10!}{(10-7)! \\times 7!} = 120\\]\namostras diferentes de tamanho \\(n = 7\\) que podem ser retiradas de uma população de tamanho \\(n = 10\\). Se tomarmos estas 120 amostras e calcularmos suas respectivas médias amostrais, teremos os resultados abaixo:\n\n\nCode\nknitr::kable(matrix(M_Allcomb7_round,nc = 12, byrow = T))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18.6\n20.3\n20.4\n20.6\n20.4\n20.6\n20.7\n22.3\n22.4\n22.6\n20.6\n20.7\n\n\n20.9\n22.4\n22.6\n22.7\n22.6\n22.7\n22.9\n24.6\n21.7\n21.9\n22.0\n23.6\n\n\n23.7\n23.9\n23.7\n23.9\n24.0\n25.7\n23.9\n24.0\n24.1\n25.9\n26.0\n22.4\n\n\n22.6\n22.7\n24.3\n24.4\n24.6\n24.4\n24.6\n24.7\n26.4\n24.6\n24.7\n24.9\n\n\n26.6\n26.7\n25.7\n25.9\n26.0\n27.7\n27.9\n28.0\n23.0\n23.1\n23.3\n24.9\n\n\n25.0\n25.1\n25.0\n25.1\n25.3\n27.0\n25.1\n25.3\n25.4\n27.1\n27.3\n26.3\n\n\n26.4\n26.6\n28.3\n28.4\n28.6\n27.0\n27.1\n27.3\n29.0\n29.1\n29.3\n30.4\n\n\n24.0\n24.1\n24.3\n25.9\n26.0\n26.1\n26.0\n26.1\n26.3\n28.0\n26.1\n26.3\n\n\n26.4\n28.1\n28.3\n27.3\n27.4\n27.6\n29.3\n29.4\n29.6\n28.0\n28.1\n28.3\n\n\n30.0\n30.1\n30.3\n31.4\n28.6\n28.7\n28.9\n30.6\n30.7\n30.9\n32.0\n32.7\n\n\n\n\n\n\n\nCode\nM_Allcomb7_df = data.frame(M = as.numeric(M_Allcomb7))\n\ngp7 <- ggplot(M_Allcomb7_df, aes(x = M)) +\n  geom_histogram(fill = 'brown3', color = 'black', bins = 10) +\n  scale_x_continuous(breaks = seq(0, 50, by = 5)) +\n  coord_cartesian(xlim = c(10, 40)) +\n  labs(x = \"Média\",\n       y = \"Frequência\") +\n  theme_classic()\n\ngp7\n\n\n\n\n\nFigura 2.3: Histograma das 120 médias amostrais obtidas a partis de amostras de tamanho n = 7\n\n\n\n\n\n\nCode\nmu_pop = mean(pop)\nN = length(pop)\nvar_pop = mean((pop - mu_pop)^2)\nsigma_pop = sqrt(var_pop)\n\nep5 = sigma_pop/sqrt(n)\nep7 = sigma_pop/sqrt(n2)\n\n\nSe compararmos os histogramas com \\(n = 5\\) e \\(n = 7\\) (Figura 2.2 e Figura 2.3), veremos que os dois resultam em estimadores acurados, pois \\(\\mu_{\\overline{X}} = \\mu\\). No entando, o intervalo de variação é menor para amostras de tamanho \\(n = 7\\). Para esta figura, os valores estão mais concentrados ao redor da média. Portanto, à medida que aumenta o tamanho amostral, diminui a dispersão das médias amostrais ao redor de \\(\\mu\\). Assim, para amostras grandes torna-se mais improvável obter uma média amostral distante da média populacional. Dizemos então que conforme aumenta o tamanho amostral, conseguimos estimativas mais precisas.\nA precisão de um estimador pode ser medida pelo Erro padrão da média (\\(\\sigma_{\\overline{X}}\\)) que pode ser calculado por:\n\\[\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nO erro padrão da média é o desvio padrão de todas as médias amostrais que poderiam ser obtidas de uma amostra com tamanho \\(n\\). Para nosso exemplo com \\(n = 5\\), \\(\\sigma_{\\overline{X}}\\) = 5.93, enquanto para \\(n = 7\\), \\(\\sigma_{\\overline{X}}\\) = 5.01. Dizemos que o último exemplo fornece estimativas mais precisas.\n\n\n\n\n\n\nErro padrão amostral\n\n\n\nNa prática científica não conhecemos o desvio padrão populacional \\(\\sigma\\) e, consequentemente, não temos obter o erro padrão populacional \\(\\sigma_{\\overline{X}}\\). No entanto, dado que temos uma amostra particular, podemos estimá-lo a partir do desvio padrão amostral \\(\\sigma_{\\overline{X}}\\) pela expressão:\n\\[s_{\\overline{X}} = \\frac{s}{\\sqrt{n}}\\]\nem que \\(s_{\\overline{X}}\\) é denominado de erro padrão amostral\n\n\n\n\n\n\n\n\n\nVídeo-aulas"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#o-modelo-normal-de-probabilidades",
    "href": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#o-modelo-normal-de-probabilidades",
    "title": "3  O modelo de distribuição normal",
    "section": "3.1 O modelo normal de probabilidades",
    "text": "3.1 O modelo normal de probabilidades\nO modelo normal de probabilidades é uma função matemática dada por:\n\\[f(x) = \\frac{1}{\\sqrt(2\\pi\\sigma^2)}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$, $x \\in \\mathbb{R} | -\\infty \\le y \\le +\\infty\\]\nA expressão envolve as quantias \\(\\mu\\) e \\(\\sigma\\), definidas como os parâmetros da distribuição que representam respectivamente, sua média e o desvio padrão. Para dizer que uma variável aleatória \\(X\\) tem distribuição normal por meio da expressão:\n\\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\)\nEsta expressão diz de \\(X\\) é normalmente distribuída (\\(\\mathcal{N}\\)) e que esta distribuição tem parâmetros \\(\\mu\\) e \\(\\sigma\\).\nA média de uma distribuição normal é o ponto central da curva e o desvio padrão mede o espalhamento das observações ao redor de \\(\\mu\\). Em um fenômeno descrito por valores baixos de \\(\\sigma\\), a maioria das observações estará próxima a \\(\\mu\\), enquanto para valores altos de \\(\\sigma\\) as observações estarão mais distantes de \\(\\mu\\). Deste modo, podemos alterar o formato da distribuição normal alterando seu parâmetro de posição (i.e. a média \\(\\mu\\)) e de dispersão (i.e. o desvio padrão \\(\\sigma\\)).\n\n\n\n\n\nFigura 3.2: Distribuições normais de probabilidade para diferentes combinações de média e desvio padrão.\n\n\n\n\nSe as observações sobre um determinado fenômeno sugerem um padrão em forma de sino, podemos buscar a melhor combinação de \\(\\mu\\) e \\(\\sigma\\) e descrever o fenômeno por meio de um modelo normal. Ao fazer isto, a distribuição normal nos ajuda a calcular as probabilidade da ocorrência de eventos futuros estarem em diferentes faixas de valores. No caso das alturas dos alunos por exemplo, vemos que a probabilidade de um aluno ter mais de \\(2\\) metros ou menos de \\(1,5\\) metros é extremamente baixa. Assumindo um modelo de distribuição normal para a distribuição de alturas, podemos utilizar o conjunto de dados para estimar os parâmetros da população e calcular quais seriam estas probabilidades.\n\n\n\n\n\n\nUm pouco de história\n\n\n\nAlguns atribuem a proposição deste modelo normal a Abraham de Moivre, um matemático Francês que chegou a a distribuição normal como uma aproximação a distribuição binomial em seu livro The Doctrine of Chances em \\(1718\\). A distribuição normal de probabilidades é simétrica, ou seja, os valores extremos são igualmente representados acima e abaixo da região central (média). Você poderá encontrar o termo bell curve em inglês, devido à sua forma de sino, ou ainda distribuição gaussiana em homenagem a Carl Friedrich Gauss um dos mais importantes matemáticos do século XXI. Gauss lidou com a distribuição normal quando desenvolveu a Teoria da distribuição dos erros observacionais no contexto do Método dos Mínimos Quadrados em \\(1823\\)."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#entendendo-a-função-normal",
    "href": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#entendendo-a-função-normal",
    "title": "3  O modelo de distribuição normal",
    "section": "3.2 Entendendo a função normal",
    "text": "3.2 Entendendo a função normal\n\n\n\nA função \\(f(x) = \\frac{1}{\\sqrt(2\\pi\\sigma^2)}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\) é uma função de densidade de probabilidade. Antes de aplicar esta distribuição para encontrar valores de probabilidade, vamos aprender simplesmente para descrever a funções de densidade assumindo valores particulares de \\(\\mu\\) e \\(\\sigma\\). Para isto, vamos tentar simular o histograma de alturas similar ao da Figura 3.1. Vamos assumir que a distribuição de alturas tenha a seguinte media e desvio padrão:\n\\(\\mu = 1.7\\) metros\n\\(\\sigma = 0.09\\) metros\nPara uma determinada altura \\(x = 1.6\\) metros, a \\(f(x)\\) assume o valor:\n\\(f(1.6) = \\frac{1}{\\sqrt(2\\pi \\times0.09^2)}e^{-\\frac{1}{2}(\\frac{1.6 - 1.7}{0.09})^2} = 2.391\\)\nEste resultado corresponde ao ponto \\(y\\) no gráfico da distribuição normal (Figura 3.3) em que \\(x = 1.6\\). Podemos encontar \\(f(x)\\) para quaisquer valores dentro dos reais \\(\\mathbb{R}\\) entre \\(-\\infty\\) e \\(+\\infty\\).\nAssim, se calcularmos \\(f(x)\\) para diferentes pontos em \\(x\\) teremos um esboço da função de densidade normal. Na Figura 3.3, por exemplo, apresentamos \\(f(x)\\) para os valores:\n\\(X = 1.4, 1.45, 1.5, 1.55, 1.6, 1.65, 1.7, 1.75, 1.8, 1.85, 1.9, 1.95, 2\\)\nassumindo \\(\\mu = 1.7\\) e \\(\\sigma = 0.09\\)\n\n\n\n\n\nFigura 3.3: Pontos na distribuição normal de densidade de probrabilidade.\n\n\n\n\n\n3.2.1 Calculando de \\(f(x)\\) no R: a função dnorm()\nNo R, os resultados acima podem ser obtidos com a função dnorm(), que fornece um modo simples para calcularmos \\(f(x)\\) na distribuição normal. Nesta função a letra ‘d’ vem de densidade da distribuição normal.\nPara encontrar \\(f(x)\\) para um dado valor fazemos simplesmente:\n\nmu <- 1.7\ndp <- 0.11\ndnorm(1.5, mean = mu, sd = dp)\n\n[1] 0.6945048\n\n\nSe quisermos obter \\(f(x)\\) para múltiplos valores de \\(x\\) podemos fazer:\n\nx <- c(1.4, 1.5, 1.6, 1.7)\ndnorm(x, mean = mu, sd = dp)\n\n[1] 0.0879777 0.6945048 2.3991470 3.6267480"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#cálculo-de-probabilidade-com-a-função-normal-de-densidade",
    "href": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#cálculo-de-probabilidade-com-a-função-normal-de-densidade",
    "title": "3  O modelo de distribuição normal",
    "section": "3.3 Cálculo de probabilidade com a função normal de densidade",
    "text": "3.3 Cálculo de probabilidade com a função normal de densidade\nEncontrar a probabilidade de uma variável aleatória \\(X\\) estar dentro de uma deteminada faixa de valores significa fazer predições a respeito da probabilidade de ocorrência de uma observação futura. Por ser uma função de probabilidade, a área abaixo de \\(f(x)\\) na distribuição normal é igual a \\(1\\).\n\\[P(-\\infty \\le X \\le +\\infty) = \\int_{-\\infty}^{+\\infty}f(x) dx = 1\\]\nAssim, se desejamos obter probabilidade de uma variável estar dentro de um determinado limite, devemos calcular a área abaixo da curva para este limite. Por exemplo, a probabilidade de uma observação em \\(X\\) estar entre \\(x_1\\) e \\(x_2\\) será:\n\n\n\n\n\nFigura 3.4: Representação das probabilidades de um intervalo da distribuição normal de densidade.\n\n\n\n\n\n3.3.1 Calculando probabilidades no R: a função pnorm()\nUsando o R, a probabilidade de amostrarmos um aluno que tenha entre menos de \\(1.5\\) metros pode ser obtida por meio da função pnorm:\n\nmu <- 1.7\ndp <- 0.11\npnorm(q = 1.5, mean = mu, sd = dp, lower.tail = TRUE)\n\n[1] 0.03451817\n\n\n\n\n\n\n\n\nArgumentos da função:\n\n\n\nq: o valor de \\(x\\)\nmean: média \\(\\mu\\) da função normal\nsd: desvio padrão \\(\\sigma\\) da função normal\nlower.tail: se a função irá retornar a probabilidade abaixo (TRUE) ou acima (FALSE) de q\nveja o menu de ajuda digitando ?pnorm no Console do R\n\n\nSe quisermos encontrar a probabilidade \\(P(X \\ge 1.5)\\) alteramos o parâmetro lower.tail\n\npnorm(q = 1.5, mean = mu, sd = dp, lower.tail = FALSE)\n\n[1] 0.9654818\n\n\nSe desejamos obter a probabilidade de \\(x\\) estar entre \\(1.5\\)m e \\(1.7\\)m podemos fazer: \\[P(1.5 \\le X \\le 1.7) = P(X \\le 1.7) - P(X \\le 1.5)\\]\nNo R temos:\n\np1 <- pnorm(q = 1.7, mean = mu, sd = dp, lower.tail = TRUE)\np2 <- pnorm(q = 1.5, mean = mu, sd = dp, lower.tail = TRUE)\npfinal <- p1 - p2\n\npfinal\n\n[1] 0.4654818\n\n\nou simplesmente:\n\ndiff(pnorm(q = c(1.7, 1.5),\n           mean = mu,\n           sd = dp,\n           lower.tail = TRUE)\n     )\n\n[1] -0.4654818\n\n\nAqui estão representados cada um dos intervalos calculados.\n\n\nCode\ndfc <- data.frame(X = seq(0,sup, length = 10000)) %>% \n  mutate(dx = dnorm(X, mean = mu, sd = dp))\n\n\ngc1 <- ggplot(dfc, mapping = aes(y = dx, x = X)) +\n   stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(data = subset(dfc, X <= 1.7), aes(y = dx), \n            fill = \"#eb4034\", color = NA, alpha = 0.5) + \n  scale_x_continuous(\n      name = 'X',\n      limits = c(1.4,2),\n      breaks = seq(1.4, 2, by = 0.05)) +\n   ylab('f(x)') +\n   annotate(geom = 'text', x = 1.5, y = 3, \n            label = bquote(\"P(X\" <= ~ 1.7 ~\")\" == .(round(p1,3))),\n            color = '#eb4034') +\n   theme_classic()\n\ngc2 <- ggplot(dfc, mapping = aes(y = dx, x = X)) +\n   stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n   geom_area(data = subset(dfc, X <= 1.5), \n             aes(y = dx), fill = \"#eb4034\", color = NA, alpha = 0.5) + \n  scale_x_continuous(\n      name = 'X',\n      limits = c(1.4,2),\n      breaks = seq(1.4, 2, by = 0.05)) +\n   ylab('f(x)') +\n   annotate(geom = 'text', x = 1.5, y = 3, \n            label = bquote(\"P(X\" <= ~ 1.5 ~\")\" == .(round(p2,3))),\n            color = '#eb4034') +\n   theme_classic()\n\n\ngc3 <- ggplot(dfc, mapping = aes(y = dx, x = X)) +\n   stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n   geom_area(data = subset(dfc, X >= 1.5 & X <= 1.7 ), \n             aes(y = dx), fill = \"#eb4034\", color = NA, alpha = 0.5) + \n  scale_x_continuous(\n      name = 'X',\n      limits = c(1.4,2),\n      breaks = seq(1.4, 2, by = 0.05)) +\n   ylab('f(x)') +\n   annotate(geom = 'text', x = 1.5, y = 3, \n            label = bquote(\"P(\" ~ 1.5 <= ~ \"X\" <= ~ 1.7 ~\")\" == .(round(pfinal,3))),\n            color = '#eb4034') +\n   theme_classic()\n  \ngc1 / gc2 / gc3"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#a-distribuição-normal-padronizada",
    "href": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#a-distribuição-normal-padronizada",
    "title": "3  O modelo de distribuição normal",
    "section": "3.4 A distribuição normal padronizada",
    "text": "3.4 A distribuição normal padronizada\nA integral para a função normal é difícil de ser calculada pois não tem solução analítica. Isto era um problema para os cientistas até meados do século \\(XX\\) que precisavam calcular valores de probabilidades para diferentes combinações de \\(\\mu\\) e \\(\\sigma\\). Naquele momento, a solução para facilitar a vida dos pesquisadores foi criar uma tabela descrevendo estas probabilidades em uma distribuição normal padronizada, ou seja para valores particulares de \\(\\mu\\) e \\(\\sigma\\). Padronizar aqui, significa transfomar cada valor \\(x_i\\) de modo que as observações resultantes tenham média igual a \\(0\\) e desvio padrão igual a \\(1\\).\nEsta transformação é apicada a cada observação \\(x_i\\), obtendo-sem um valor de \\(z_i\\) correspondente por meio da expressão.\n\\[z_i = \\frac{x_i - \\mu}{\\sigma}\\]\nA transformação \\(Z\\) é útil, pois ainda que seja difícil calcular as probabilidades para uma variável aleatória \\(X\\), após a transformação teremos uma variável \\(Z\\) para a qual os valores de probabilidade estão tabelados. Deste modo, \\(Z\\) é uma variável aleatória com \\(\\overline{z} = 0\\) e \\(s = 1\\) tal que:\n\\[Z \\sim \\mathcal{N}(0,\\,1)\\]\nApós a transformação \\(Z\\) nos exemplos sobre altura dos alunos e da temperatura mensal temos:\n\n\nCode\nie <- ie %>% \n   mutate(ALTURA_z = (ALTURA - mean(ALTURA, na.rm = T))/sd(ALTURA, na.rm = T))\ntemp <- temp %>% \n   mutate(tm_z = (tm - mean(tm, na.rm = T))/sd(tm, na.rm = T))\n\naltz_plt <- ggplot(ie, aes(x = ALTURA_z)) +\n   geom_histogram(aes(y = after_stat(density)), \n                  fill = 'dodgerblue4', \n                  color = 'black', bins = 10) +\n   stat_function(fun = dnorm, \n                 args = list(mean = mean(ie$ALTURA_z, na.rm = T),\n                                          sd = sd(ie$ALTURA_z, na.rm = T))) +\n   labs(x = \"Distribuição Z\",\n        y = \"Frequencia relativa\") +\n   theme_classic()\n\ntempz_plt <- ggplot(temp, aes(x = tm_z)) +\n   geom_histogram(aes(y = after_stat(density)),\n                  fill = 'dodgerblue4', \n                  color = 'black', bins = 10) +\n   stat_function(fun = dnorm, \n                 args = list(mean = mean(temp$tm_z, na.rm = T),\n                                          sd = sd(temp$tm_z, na.rm = T))) +\n   labs(x = \"Distribuição Z\",\n        y = \"Frequencia relativa\") +\n   theme_classic()\n\n(alt_plt | temp_plt) / \n  (altz_plt | tempz_plt)\n\n\n\n\n\nFigura 3.5: Distribuição das variáveis originais e após a transformação Z.\n\n\n\n\n\n\n\n\n\n\nEscore Z\n\n\n\nO Escore Z pode ser apresentado como uma medida de posição de uma observação na amostra (\\(z_i\\)) que representava uma medida relativa desta observação com relaçao à média e ao desvio padrão do conjunto de dados. Por exemplo, um valor de \\(z_i = 2\\) significa que a observação original \\(x_i\\) está \\(2\\) desvios padrões acima de sua respectiva média \\(\\mu\\).\n\n\n\n3.4.1 Probabilidades em uma distribuição normal padronizada\nNos dois exemplos anteriores, verifica-se que todas as observações estão situadas, aproximadamente, entre \\(z = -3\\) e \\(z = +3\\). De fato, a distribuição normal padronizada ou distribuição Z tem propriedades bem conhecidas. Como sua média é \\(\\mu = 0\\) e seu desvio padrão é \\(\\sigma = 1\\), a maior parte das observações fica limitada entre \\(z = -3\\) e \\(z = +3\\). Para ser exato, podemos descrever as probabilidades de uma observação estar dentro de alguns limites conhecidos. Por exemplo, \\(95\\%\\) das observações estará entre \\(z = -1.96\\) e \\(z = +1.96\\), isto é,\n\\[P(-1.96 \\le Z \\le +1.96) = 0.95\\]\nDe forma similar, \\(90\\%\\) da área central da curva se encontra entre \\(z = -1.64\\) e \\(z = +1.64\\). Estes e outros limites na distribuição normal padronizada podem ser verificados na figura abaixo.\n\n\nCode\n# Ver função completa no arquivo 'scripts/normal_empirica_gg.r'\nnormal_empirica_gg(xlabels = c(-4:4))\n\n\n\n\n\nFigura 3.6: Áreas de probabilidade em uma distribuição Normal Padronizada (Distribuição Z).\n\n\n\n\nVamos exemplificar o uso da distribuição \\(Z\\) no cálculo de probabilidades utilizando os dados de altura dos alunos. Para estes dados, iremos encontrar \\(P(X \\le 1.5)\\). Este procedimento consiste de:\n\n\nCode\nmu <- 1.7\ndp <- 0.11\nx <- 1.5\nz_1.5 <- (x - mu)/dp\n\n\n\nTransformar \\(x = 1.5\\) em \\(z_{1.5}\\) por meio de \\(z_{1.5} = \\frac{1.5 - 1.7}{0.11} = -1.818\\);\n\n\n\nCode\nmu <- 1.7\ndp <- 0.11\nx <- 1.5\nz_1.5 <- (x - mu)/dp\n\nz_1.5\n\n\n[1] -1.818182\n\n\n\nEncontrar encontrar \\(P(Z \\le z_{1.5}) = P(Z \\le -1.818) = 0.0345182\\).\n\n\n\nCode\npnorm(q = z_1.5, mean = 0, sd = 1, lower.tail = TRUE)\n\n\n[1] 0.03451817\n\n\nCompare este resultado com o obtido anteriormente para verificar que é equivalente a \\(P(X \\le 1.5)\\).\n\n\n\n\n\n\nA transformação \\(Z\\)\n\n\n\nSuponha uma variável aleatória \\(X\\) nomalmente distribuída conforme \\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\). Desejamos encontrar \\(m\\) tal que:\n\\(P(X \\le m) = \\alpha\\)\n\n\\(\\alpha\\) aqui representa um valor de probabilidade qualquer determinada pela área na distribuição normal abaixo de \\(m\\).\n\nAo aplicar a transformação \\(Z\\) teremos:\n\\(P(\\frac{X - \\mu}{\\sigma} \\le \\frac{m - \\mu}{\\sigma}) = \\alpha\\)\ncomo \\(\\frac{X - \\mu}{\\sigma} = Z\\) temos que:\n\\(P(Z \\le \\frac{m - \\mu}{\\sigma}) = \\alpha\\)\nPor meio desta expressão, você pode encontar \\(m\\) uma vez fornecido \\(\\alpha\\) ou encontrar \\(\\alpha\\), desde que seja fornecido \\(m\\).\nO mesmo vale se quisermos encontrar a probabilidade determinada por um intervalo definido de \\(m\\) até \\(n\\) (\\(m < n\\)). Para isto fazemos:\n\\(P(m \\le X \\le n) = \\alpha\\)\n\\(P(\\frac{m - \\mu}{\\sigma} \\le \\frac{X - \\mu}{\\sigma} \\le \\frac{n - \\mu}{\\sigma}) = \\alpha\\)\n\\(P(\\frac{m - \\mu}{\\sigma} \\le Z \\le \\frac{n - \\mu}{\\sigma}) = \\alpha\\)\n\n\n\n\n3.4.2 Tabela \\(Z\\)\nAo utilizarmos um software estatístico não é necessário fazer esta transformação. A transformação \\(Z\\) era necessária na ausência de ferramentas computacionais, ou seja, quando a única opção era utilizarmos a Tabela \\(Z\\) para evitar cálculos tediosos considerando cada combinação de \\(\\mu\\) e \\(\\sigma\\).\nA Tabela Z disponibiliza os valores de probabilidade para um grande número de valores e é apresentada na grande maioria dos livros de estatística.\nVocê pode utilizar a Tabela \\(Z\\) para encontrar \\(P(X \\le 1.5)\\). Note que o valor transformado é \\(z_{1.5} = -1.818\\). Este será o valor que iremos buscar na tabela. Para isto:\n\nEncontre a página que oferece valores negativos, uma vez que \\(z_{1.5} < 0\\);\nNa coluna 1 desta página (coluna z) encontre a linha -1.8 que refere-se à unidade, e à primeira casa decimal de \\(z_{1.5}\\);\nEncontre a coluna 0.02 (quarta coluna da tabela \\(Z\\)) que apresenta a segunda casa decimal de \\(z_{1.5}\\). Isto nos leva ao valor mais próximo do calculado (\\(z_{1.5} = -1.818\\)).\nCruze a linha escolhida no item 3 com a coluna escolhida no item 4. Você irá encontrar o valor \\(0,0344\\). Este valor e a probabilidade de obtermos um valor de \\(z \\le 1.5\\) na distribuição normal padronizada, ou seja, \\(P(Z \\le z_{1.5})\\). A diferença entre este valor e o encontrado com o R se deve unicamente ao limite de precisão na Tabela \\(Z\\)."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#exercícios-resolvidos",
    "href": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#exercícios-resolvidos",
    "title": "3  O modelo de distribuição normal",
    "section": "3.5 Exercícios resolvidos",
    "text": "3.5 Exercícios resolvidos\nImporte o conjunto de dados rhamdioglanis.csv\n\nrh <- read_delim('datasets/rhamdioglanis.csv', delim = ';',\n                 locale = locale(decimal_mark = ','))\n\n\n3.5.1 Distribuição de comprimento\nAs comunidades de peixes em riachos de cabeceira são compostas por espécies de pequeno porte. Rhamdioglanis transfasciatus é uma destas espécies, desconhecida do público em geral, porém muito abundante em pequenos riachos bem preservados. Dados de captura sugerem que o tamanho dos indivíduos pode ser razoavelmente bem descrito por um modelo de distribuição normal.\n\n\nCode\nggplot(rh, aes(x = Comprimento)) +\n   geom_histogram(aes(y = after_stat(density)),\n                  fill = 'dodgerblue4', color = 'black', bins = 15) +\n   stat_function(fun = dnorm, args = list(mean = mean(rh$Comprimento),\n                                          sd = sd(rh$Comprimento))) +\n   labs(x = 'Comprimento de Rhamdioglanis transfasciatus (cm)',\n        y = 'Densidade') +\n   theme_classic()\n\n\n\n\n\n\n\n\nSuponha o comprimento desta espécie tenha uma distribuição normal com \\(\\mu = 10\\) cm e \\(\\sigma = 3\\) cm. Encontre:\n\nA probabilidade de capturar um indivíduo maior de 14 cm de comprimento, \\(P(X \\ge 14)\\).\nA probabilidade de capturar um indivíduo menor de 5 cm de comprimento, \\(P(X \\le 5)\\).\nA probabilidade de encontrar um indivíduo entre 5 e 14 cm, \\(P(5 \\le X \\le 14)\\).\nSe um trecho de riacho contém 800 indivíduos, quantos são maiores que 14 cm de comprimento.\n\nRESOLUÇÃO\n\n\n\n\n\n\n\n\n\n\\(P(X \\ge 14)\\)\n\n\n\n\n\nVamos encontrar o respectivo valor de \\(Z\\) pela transformação\n\\(z_{14} = \\frac{14 - 10}{3} = 1.33\\)\nNa tabela \\(Z\\) procuramos a linha que mostra a unidade e \\(1^a\\) casa decimal de \\(1.33\\) e em seguida encontramos a coluna que representa a \\(2^a\\) casa decimal de \\(1.33\\). Cruzando linha e coluna encontramos o valor \\(0,9082\\). Note que este valor representa a área abaixo de 1.33, isto é, \\(P(Z \\le z_{14})\\). No entanto, queremos \\(P(Z \\ge z_{14})\\) que representa a área da curva acima de \\(1.33\\). Para isto basta fazermos \\(1 - 0,9082\\).\nDeste modo, \\(P(Z \\ge z_{14}) = 1 - P(Z \\le z_{14}) = 1 - 0,9082 = 0.0918\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nii. \\(P(X \\le 5)\\)\n\n\n\n\n\n\\(z_{5} = \\frac{5 - 10}{3} = -1.67\\)\nNa tabela \\(Z\\) procuramos a linha que mostra a unidade e \\(1^a\\) casa decimal de \\(-1.67\\) e em seguida encontramos a coluna que representa a \\(2^a\\) casa decimal de \\(-1.67\\). Cruzando linha e coluna encontramos o valor \\(0,0475\\) que representa a área desejada.\nDeste modo, \\(P(X \\le 5) = P(Z \\le z_{5}) = 0,0475\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niii. \\(P(5 \\le X \\le 14)\\)\n\n\n\n\n\nVamos subtrair as quantias \\(P(Z \\le 14) - P(Z \\le 5)\\)\nEstes valores já foram encontrados nos itens anteriores, de modo que basta fazermos:\n\\(P(5 \\le X \\le 14) = 0,9082 - 0,0475 = 0.8607\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv. Indivíduos maiores que 14 cm de comprimento\n\n\n\n\n\nSe a proporção de indivíduos acima de 14 é \\(P(X > 14) = 0.0918\\) e a população tem \\(N = 800\\) indivíduos, teremos:\n\\(0.0918 \\times 800 = 73\\) indivíduos maiores que 14 cm.\n\n\n\n\n\n\n\n\n\nRESOLUÇÃO no R\n\n\n\n\n\nO exercício pode ser resolvido pelo R por meio da função pnorm.\n\nmu <- 10\nsigma <- 3\nN <- 800\nla <- 14\nlb <- 5\n\n\ni. \\(P(Z \\ge 14)\\)\n\npnorm(q = la, mean = mu, sd = sigma, lower.tail = FALSE)\n\n[1] 0.09121122\n\n\n\nii. \\(P(Z \\le 5)\\)\n\npnorm(q = lb, mean = mu, sd = sigma, lower.tail = TRUE)\n\n[1] 0.04779035\n\n\n\niii. \\(P(5 \\le X \\le 14)\\)\n\ndiff(\n   pnorm(q = c(lb, la),\n         mean = mu,\n         sd = sigma,\n         lower.tail = TRUE)\n   )\n\n[1] 0.8609984\n\n\n\niv. Número de indivíduos maiores que \\(14\\) cm de comprimento\n\npg_la <- pnorm(q = la, mean = mu, sd = sigma, lower.tail = FALSE)\n\nN * pg_la\n\n[1] 72.96898\n\n\n\n\n\n\n\n3.5.2 Intervalos em uma distribuição normal\nSuponha variável aleatória \\(X\\) normalmente distribuída conforme com \\(\\mu = 50\\) e \\(\\sigma = 10\\). Encontre:\n\nO valor de \\(a\\) tal que \\(P(X \\le a) = 0,10\\).\nO valor de \\(b\\) tal que \\(P(X \\ge b) = 0,85\\).\nO intervalo simétrico ao redor da média delimitado por \\(c\\) e \\(d\\) (\\(c < d\\)), que contém \\(95\\%\\) da área sob a curva.\nO valor de \\(e\\) tal que \\(P(50-e \\le X \\le 50+e) = 0.99\\)\n\n\n\n\n\nRESOLUÇÃO\nVeja que neste exercício, foram oferecidos valores de probabilidades e solicitado que você obtivesse os limites em uma distribuição normal específica. Este processo é oposto ao do excercício anterior.\n\n\n\n\n\n\ni. O valor de \\(a\\)\n\n\n\n\n\nSe \\(P(X \\le a) = 0,10\\), a área da curva abaixo de \\(a\\) é \\(0,10\\). Procurando por este valor na tabela \\(Z\\) vemos que o valor mais próximo é \\(0,1003\\) que corresponde a um escore \\(z = -1,28\\). Vamos utilizar este valor para encontrar sua correspondência para a variável aleatória \\(X\\) que tem média \\(\\mu = 50\\) e desvio padrão \\(\\sigma = 10\\).\n\\(z = \\frac{a - \\mu}{\\sigma} :: -1,28 = \\frac{a - 50}{10}\\)\n\\(a = (-1,28 \\times 10) + 50 = 37.2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nii. O valor de \\(b\\)\n\n\n\n\n\nSe \\(P(X \\ge b) = 0,85\\), a área abaixo de \\(b\\) que devemos encontrar na tabela \\(Z\\) é \\(1 - 0,85 = 0.15\\). Vemos que o valor mais próximo é \\(0,1492\\) que corresponde a \\(z = -1,04\\). Ao utilizar este resultado na expressão abaixo temos:\n\\(z = \\frac{b - \\mu}{\\sigma} :: -1,04 = \\frac{b - 50}{10}\\)\n\\(b = (-1,04 \\times 10) + 50 = 39.6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO intervalo simétrico ao redor da média delimitado por \\(c\\) e \\(d\\) (\\(c < d\\)), que contém \\(95\\%\\) da área sob a curva.\n\n\n\n\n\nSe entre \\(c\\) e \\(d\\) está \\(95\\%\\) da área da curva, temos uma área de \\(1 - 0,95 = 0,05\\) fora da curva. Como o intervalo é simétrico, teremos \\(0,025\\) abaixo de \\(c\\) e \\(0,025\\) acima de \\(d\\).\nAo procurar na tabela \\(Z\\) por \\(0,025\\) encontraremos \\(z = -1,96\\) que equivale ena distribuição de X a:\n\\(z = \\frac{c - \\mu}{\\sigma} :: -1,96 = \\frac{c - 50}{10}\\)\n\\(c = (-1,96 \\times 10) + 50 = 30.4\\)\nNovamente, como o intervalo é simétrico e a dsitribuição de \\(Z\\) é centrada em zero, o ponto \\(d\\) será de +\\(1,96\\) que resulta em:\n\\(z = \\frac{d - \\mu}{\\sigma} :: +1,96 = \\frac{d - 50}{10}\\)\n\\(d = (+1,96 \\times 10) + 50 = 69.6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv. O valor de \\(e\\) tal que \\(P(50-e \\le X \\le 50+e) = 0.99\\)\n\n\n\n\n\nPodemos fazer aqui:\n\\(P(50-e \\le X \\le 50+e) = P(\\frac{50-e - \\mu}{\\sigma} \\le \\frac{X-\\mu}{\\sigma} \\le \\frac{50+e-\\mu}{\\sigma}) = 0.99\\)\ncomo \\(\\mu = 50\\) e \\(\\sigma = 10\\) temos:\n\\(P(\\frac{-e}{10} \\le Z \\le \\frac{e}{10}) = 0.90\\)\nComo a área central ocupa \\(0,99\\) da distribuição, restam \\(0,005\\) na cauda superior e \\(0,005\\) na cauda inferior:\n\n\n\n\n\nPara encontrar \\(-e\\) buscamos por \\(0,005\\) na tabela \\(Z\\) e encontramos \\(0,0051\\) como valor mais próximo, referente a \\(z_{-e} = -2,57\\). Substituindo na equação temos:\n\\(\\frac{-e}{10} \\le -2,57 :: -e = -2,57 \\times 10 :: e = 25,7\\)\n*Note na figura acima que os limite das áreas em azul são:\n\\(\\mu - e = 50 - 25.7 = 24.3\\) e\n\\(\\mu - e = 50 + 25.7 = 75.7\\)\n\n\n\n\n\n\n\n\n\nRESOLUÇÃO no R\n\n\n\n\n\nO exercício pode ser resolvido pelo R por meio da função qnorm.\n\nEm qnorm, o ‘q’ vem de quantis da distribuição normal.\n\n\nmu = 50\nsigma = 10\n\n(a <- qnorm(p = 0.10, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 37.18448\n\n(b <- qnorm(p = 1-0.85, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 39.63567\n\n(c <- qnorm(p = (1-0.95)/2, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 30.40036\n\n(d <- qnorm(p = (1-0.95)/2, mean = mu, sd = sigma, lower.tail = FALSE))\n\n[1] 69.59964\n\n(e <- -qnorm(p = (1-0.99)/2, mean = mu, sd = sigma, lower.tail = TRUE) + 50)\n\n[1] 25.75829\n\n\n\n\n\n\n\n3.5.3 Quantos desvios padrões?\nSuponha uma variável aleatória normalmente distribuída representada por \\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\), determine:\n\nO valor de \\(a\\) tal que \\(P(X < a) = 0,20\\).\n\\(P(X \\le \\mu + 2\\sigma)\\).\nO valor de \\(c\\) tal que \\(P(\\mu -c\\sigma \\le X \\le \\mu +c\\sigma) = 0.99\\)\n\nRESOLUÇÃO\n\n\n\n\n\n\ni. O valor de \\(a\\) tal que \\(P(X < a) = 0,20\\).\n\n\n\n\n\n\\(P(X < a) = P(\\frac{X - \\mu}{\\sigma} < \\frac{a - \\mu}{\\sigma}) = P(Z < \\frac{a - \\mu}{\\sigma}) = 0,20\\)\nProcurando pelo valor de \\(z\\) que delimita \\(0,20\\) da área abaixo de \\(a\\) encontramos por \\(z = -0,84\\), de modo que:\n\\(-0,84 = \\frac{a - \\mu}{\\sigma}\\)\n\\(a = \\mu -0,84\\sigma\\)\n\n\n\n\n\n\n\n\n\nii. \\(P(X \\le \\mu + 2\\sigma)\\)\n\n\n\n\n\nA expressão \\(\\mu + 2\\sigma\\) nos diz que o limite de interesse está \\(2\\) desvios padrões acima de \\(\\mu\\). Ao procurar pelo valor de \\(z = 2,0\\) na tabela \\(Z\\), veremos que a probabilidade de interesse é \\(P(X \\le \\mu + 2\\sigma) = 0,9772\\)\n\n\n\n\n\n\n\n\n\niii. O valor de \\(c\\) tal que \\(P(\\mu -c\\sigma \\le X \\le \\mu +c\\sigma) = 0.99\\)\n\n\n\n\n\nDesenvolvendo esta expressão teremos\n\\(P(-c \\le \\frac{X - \\mu}{\\sigma} \\le +c) = P(-c \\le Z \\le +c) = 0.99\\)\nFora deste intervalo simétrico, teremos uma área de \\(0,005\\) na cauda inferior e \\(0,005\\) na cauda superior da distribuição \\(Z\\).\nAo procurar por \\(0,005\\) na tabela \\(Z\\) encontramos \\(z = -2,57\\), de modo que \\(c = 2,57\\)."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#exercícios-propostos",
    "href": "qmd/02-Inferencia_teste_hipoteses/01-norm.html#exercícios-propostos",
    "title": "3  O modelo de distribuição normal",
    "section": "3.6 Exercícios propostos",
    "text": "3.6 Exercícios propostos\nLeia o tópico 7.4.2 O Modelo Normal em Bussab and Morettin (2010) (pag. 176 a 181) e faça os exercícios 14 a 20 da página 184.\n\n\n\n\n\n\n\nVídeo-aulas\n\n\n\n\n\n\n\n\n\n\nBussab, Wilton de O., and Pedro A. Morettin. 2010. Estatśitica Básica. 6a ed. Saraiva."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html",
    "href": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html",
    "title": "4  Distribuição das médias amostrais",
    "section": "",
    "text": "5 Distribuição das médias amostrais\nVamos retomar algumas ideias discutidas no Capítulo 1 e Capítulo 2, quando apresentamos a distribuição das médias amostrais e o ciclo de amostragem \\(\\Rightarrow\\) inferência estatística. Ao amostrar uma população estatística por meio de um experimento, seremos capazes de calcular estatísticas descritivas desta população. A média amostral \\(\\overline{X}\\) é uma destas estimativas, mas a mesma ideia vale para qualquer outra estatística \\(\\theta\\).\nNeste processo, o resultado de um experimento pode ser visto como uma observação particular de uma população de experimentos que podem ser reproduzidos sob as mesmas condições. A estimativa obtida deste experimento é portanto, somente uma entre uma população de estimativas que o experimento pode gerar. A inferência estatística consiste em entender o que podemos esperar como resultados possíveis desta população de experimentos."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html#teorema-central-do-limite",
    "href": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html#teorema-central-do-limite",
    "title": "4  Distribuição das médias amostrais",
    "section": "5.1 Teorema Central do Limite",
    "text": "5.1 Teorema Central do Limite\nNo Capítulo 2 apresentamos a distribuição de médias como uma distribuição normal, centrada na média populacional \\(\\mu\\) e com desvio padrão igual a \\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{n}}\\). Este resultado é previsto pelo Teorema Central do Limite (TCL) que fornece um modelo teórico para o comportamento esperado da média amostral de um experimento.\n\n\n\n\n\n\nTeorema Central do Limite: definição\n\n\n\nSeja uma população estatística com média \\(\\mu\\) e desvio padrão \\(\\sigma\\). A distribuição das médias amostrais desta população tenderá a apresentar uma distribuição normal de probabilidades com média \\(\\mu\\) e desvio padrão \\(\\frac{\\sigma}{\\sqrt(n)}\\) à medida que o tamanho amostral \\(n\\) aumenta, ainda que a distribuição das observações originais não possua uma distribuição normal.\n\n\nSegundo o TCL, as médias amostrais \\(\\overline{X}\\) de um experimento distribuem-se como:\n\\[\\overline{X} \\sim \\mathcal{N}(\\mu_{\\overline{X}},\\,\\sigma^{2}_{\\overline{X}})\\]\nem que \\(\\mu_{\\overline{X}} = \\mu\\) \\(\\sigma^{2}_{\\overline{X}} = \\frac{\\sigma^2}{n}\\)\nNote que a variância de \\(\\overline{X}\\) depende do tamanho amostral \\(n\\). Isto justifica o que será discutido no tópico Introdução à suficiência amostral do Capítulo 5.\n\n5.1.1 Probabilidades na amostra original e na distribuição de médias\n\n\n\nSeja uma variável \\(X\\) qualquer com \\(\\mu = 50\\) e \\(\\sigma = 10\\). As figuras abaixo comparam as probabilidades acima de \\(x_1 = 55\\) para as observações originais e para as distribuições de médias amostrais de tamanho \\(n_1 = 2\\) e \\(n_2 = 10\\).\n\n\n\n\n\nFigura 5.3: Probabilidades na amostra original e na distribuição de médias.\n\n\n\n\nNote que existe uma probabilidade razoável de que uma determinada observação em \\(X\\) esteja acima de \\(55\\), \\(P(X \\leq 55) = 0.309\\). No entando se tomarmos ao acaso uma amostra de tamanho \\(n_1 = 2\\), a probabilidade de que a média destas duas amostras esteja acima de \\(55\\) diminui para \\(P(\\overline{X} \\leq 55) = 0.24\\). Se tormarmos uma amostra ainda maior (\\(n_2 = 10\\)), a probabilidade se reduz ainda mais para \\(P(\\overline{X} \\leq 55) = 0.057\\).\nVemos portanto, como mencionado no Capítulo 2, que a precisão de um experimento aumenta à medida que aumentamos o tamanho amostral, pois para amostras grandes, a probabilidade de obtermos um \\(\\overline{X}\\) distante de \\(\\mu\\) torna-se cada vez menor.\n\n\n5.1.2 Distribuições não-normais\nO TCL é válido inclusive para distribuições não-normais. Isto torna a distribuição normal uma das mais importantes em inferência estatística, pois ainda que o resultado de um experimento particular seja descrito por qualquer outro modelo de probabilidades, as médias das amostras deste experimento seguirão uma distribuição normal, à medida que \\(n\\) aumenta. Isto justifica muitos dos processos de análise e inferência estatística que serão descritos nos capítulos posteriores.\nA fig-tcl-non-normal, simula a distribuição de médias amostrais para variáveis com diferentes distribuições de probabiidades e tamanhos crescentes de \\(n\\). Podemos observar que independente do formato da distribuição original, a distribuição das médias amostrais tende à normalidade. O padrão normal aparece mais rápido se a distribuição original é simétrica. Ainda que para populações estatísticas com distribuições assimétricas, seja necessário um tamanho amostral maior para que se alcance a normalidade, a figura mostra que a partir de \\(n = 30\\) todas as distribuições parecem se aproximar do que seria esperado um modelo normal.\n\n\n\n\n\nFigura 5.4: Demostração empírica do Teorema Central do Limite, mostrando a tendência à normalidade de \\(\\bar{X}\\) à medina que \\(n\\) aumenta."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html#exercícios-resolvidos",
    "href": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html#exercícios-resolvidos",
    "title": "4  Distribuição das médias amostrais",
    "section": "5.2 Exercícios resolvidos:",
    "text": "5.2 Exercícios resolvidos:\n\n5.2.1 Tamanho médio de robalos no mercado de peixes\nEm 2014 no estuário do rio Itanhaém - SP foi pescado o “maior robalo já encontrado” (G1 Santos). O peixe tinha \\(133\\) cm e \\(27,8\\) kg . Em 2018 em Bertioga, também no litoral de SP: “Robalo ‘gigante’ quebra recordes e vira atração” (G1 Santos) pesando \\(33\\) kg. Finalmente, em “uma das salas da Colônia de Pesca Z2 de Atafona” RJ está uma imagem de um robalo de \\(28\\) kg capturado muitas décadas atrás (Ambiente Cult)\n\n\n\n\n\n\n\n(a) Itanhaém 2014\n\n\n\n\n\n\n\n(b) Bertioga 2018\n\n\n\n\n\n\n\n(c) Atafona, sem data\n\n\n\n\nFigura 5.5: Grandes robalos\n\n\nEstas capturas viram notícias pois são inusitadas. Dados de desembarque sugerem que a distribuição de tamanho de robalos comumente capturados está muito abaixo destes limites (Figura 5.6) (Ximenes-Carvalho 2006) ( Acesse aqui o trabalho completo).\n\n\nCode\nTabelaI <- data.frame(\n  compmedio = c(25.2, 34.4, 40.7, 46.3, 51.7, 56.5, 61.2, 65.8, 70.3, 73.4, 76.2),\n  N = c(130,130,112,100,82,64,47,30,18,12,6)\n)\n\ntabelaI_plt <- ggplot(data = TabelaI, mapping = aes(x = compmedio, y = N)) +\n   geom_col(fill = 'dodgerblue4', color = 'black') +\n   labs(y = 'Número de indivíduos analisados',\n        x = 'Comprimento médio (cm)') +\n   theme_classic()\n\n\n\n\nCode\ntabelaI_plt\n\n\n\n\n\nFigura 5.6: Dados de desembarque no Mercado de São Pedro (Niterói, RJ). Extraídos de XIMENES-CARVALHO, 2006.\n\n\n\n\n\n\n\nA distribuição de tamanhos na Figura 5.6 é altamente assimétrica e claramente não-normal. Um dos motivos para este forte grau de assimetria deve-se ao limite inferior de captura, pois a captura e comercialização de animais muito pequenos é proibida.\nSuponha que o comprimento de robalos (\\(L\\)) disponíveis para compra tenha média \\(\\mu = 44.1\\) e desvio padrão \\(\\sigma = 13.4\\). Você compra 10 robalos escolhidos ao acaso dos que estão disponíveis. Qual a probabilidade de que:\n\nO tamanho médio de uma compra esteja acima de \\(52,4\\) cm, isto é \\(P(\\overline{L} > 52,4)\\)?\nEm \\(95\\%\\) das vezes que fizer a compra, determine o intervalo simétrico que conterá o tamanho médio dos robalos selecionados, isto é \\(P(a \\le \\overline{L} \\le b) = 0,95\\)\nResponda novamente aos itens i. e ii. no caso de sua compra constar de \\(4\\) robalos.\n\nRESOLUÇÃO\nAinda que a distribuição original claramente não siga uma distribuição normal, podemos utilizar o TCL para estimarmos as probabilidades de obter uma média amostral \\(\\overline{X}\\) a determinada distância de \\(\\mu\\). Para isto, no entanto devemos recordar que o desvio padrão das médias amostrais será dado por: \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\).\n\n\n\n\n\n\ni. \\(P(\\overline{L} > 52,4)\\)\n\n\n\n\n\nCom base no TCL, uma amostra de \\(n = 10\\) terá média normalmente distribuída com parâmetros \\(\\mu\\) e \\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{10}}\\). Podemos assim, realizar a transformação \\(Z\\) como segue:\n\\(Z_{\\overline{L}} = \\frac{\\overline{L} - \\mu}{\\sigma_{\\mu}} = \\frac{\\overline{L} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n\\(Z_{\\overline{L}} = \\frac{52,4 - 44.1}{\\frac{13.4}{\\sqrt{10}}} = 1.96\\)\n\nNote que o denomidador aqui é diferente do que fizemos no Capítulo 3, pois aqui estamos falando da distribuição das médias amostrais \\(\\overline{L}\\) e não nas observações individuais \\(L\\).\n\nSe buscarmos na Tabela Z, veremos que a área da distribuição normal padronizada abaixo de \\(1.96\\) é de \\(0,975\\). Consequentemente \\(P(\\overline{L} > 52,4) = 1 - 0,975 = 0,025\\)\n\n\n\n\n\n\n\n\n\nii. \\(P(a \\le \\overline{L} \\le b) = 0,95\\)\n\n\n\n\n\nSe o intervalo é simétrico e contém \\(0,95\\) das observações, restam \\(0,025\\) em cada uma das caudas. Vimos no item anterior que \\(z = 1,96\\) que delimita \\(0,025\\) da cauda superior. Portanto os limites aqui serão dados por: \\(a = -1.96\\) e \\(b = 1.96\\). Na distribuição original estes limites resultarão em:\n\\(-1,96 = \\frac{a - 44.1}{\\frac{13.4}{\\sqrt{10}}}:: a = 44.1 -1,96 \\frac{13.4}{\\sqrt{10}} = 35.8\\) cm\ne\n\\(+1,96 = \\frac{b - 44.1}{\\frac{13.4}{\\sqrt{10}}}:: b = 44.1 +1,96 \\frac{13.4}{\\sqrt{10}} = 52.4\\) cm\n\n\n\n\n\n\n\n\n\nReduzindo para \\(n = 4\\) robalos\n\n\n\n\n\nAqui você deve repetir exatamente os passos de i. e ii. substituindo \\(n = 10\\) por \\(n = 4\\).\n\n\n\n\n\n\n\n\n\nRESOLUÇÃO no R:\n\n\n\n\n\n\n\\(P(\\overline{L} > 52,4)\\)\n\n\npnorm(52.4, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = FALSE)\n\n[1] 0.02507255\n\n\n\n\\(P(a \\le \\overline{L} \\le b) = 0,95\\)\n\n\na <- qnorm((1-0.95)/2, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = TRUE)\na\n\n[1] 35.79475\n\nb <- qnorm((1-0.95)/2, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = FALSE)\nb\n\n[1] 52.40525\n\n\n\nRepita os comandos acima para \\(n = 4\\)\n\n\n\n\n\n\n\n\n\n\nAtenção\n\n\n\nNeste exercício aplicamos o que aprendemos sobre o TCL para estimar probabilidades de eventos, assumindo a distribuição normal das médias amostaris. É importante resaltar, no entanto, que a distribuição altamente assimétrica do comprimento dos robalos (Figura 5.6) e um tamanho amostral reduzido (\\(n = 10\\) e \\(n = 4\\)) dificilmente justificariam o uso do TCL como vemos na Figura 5.4."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html#exercícios-propostos",
    "href": "qmd/02-Inferencia_teste_hipoteses/02-tcl.html#exercícios-propostos",
    "title": "4  Distribuição das médias amostrais",
    "section": "5.3 Exercícios propostos",
    "text": "5.3 Exercícios propostos\nLeia dos tópicos 10.6 Estatísticas e Parâmetros a 10.8 Distribuição Amostral da Média em (Bussab and Morettin 2010) (pag. 271 a 281) e faça os exercícios 7 a 10 da página 281.\n\n\n\n\n\n\n\nVídeo-aulas\n\n\n\n\n\n\n\n\n\n\nBussab, Wilton de O., and Pedro A. Morettin. 2010. Estatśitica Básica. 6a ed. Saraiva.\n\n\nXimenes-Carvalho, Maria Odete. 2006. “Idade e Crescimento Do Robalo-Flecha, Centropomus Undecimalis (BLOCH, 1792) e Robalo-Peva, Centropomus Parallelus (POEY, 1860) (OSTEICHTHYES: CENTROPOMIDAE), No Sudeste Do Brasil.” PhD thesis, Instituto de Ciências do Mar, Universidade Federal do Ceará."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/03-inferencia.html#estimação-pontual-e-estimação-intervalar",
    "href": "qmd/02-Inferencia_teste_hipoteses/03-inferencia.html#estimação-pontual-e-estimação-intervalar",
    "title": "5  Estimando a média populacional",
    "section": "5.1 Estimação pontual e estimação intervalar",
    "text": "5.1 Estimação pontual e estimação intervalar\nA média \\(\\overline{X}\\) obtida a partir de uma determinada amostra varia em função das características das unidades amostrais que foram selecionadas (Capítulo 2). Portanto, \\(\\overline{X}\\) não será igual à média \\(\\mu\\). No entanto, o TLC (Capítulo 4) nos garante que a distribuição esperada das médias amostrais terá uma distribuição normal e que a média das médias (\\(\\mu_{\\overline{X}}\\)) será igual a \\(\\mu\\). Vimos ainda que o desvio padrão da distribuição das médias amostrais (conhecido como erro padrão - \\(\\sigma_{\\overline{X}}\\)) dependerá do tamanho da amostra \\(n\\), de acordo com a expressão:\n\\[\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nUma vez que não conhecemos \\(\\mu\\), temos que estimá-lo a partir da amostra. Neste caso, \\(\\overline{X}\\) será nossa melhor estimativa da média populacional. Dizemos que \\(\\overline{X}\\) é o estimador pontual de \\(\\mu\\).\nComo \\(\\overline{X}\\) varia em função de nossa amostra particular, devemos obter além da estimativa pontual, uma estimativa intervalar que nos é fornecida pelo intervalo de confiança.\n\n5.1.1 Intervalo de confiança\n\n\n\n\n\n\nIntervalo de confiança: definição\n\n\n\nÉ o intervalo de valores associado a um determinado nível de significância (\\(\\alpha\\)). Quando dizemos que um intervalo foi calculado a um nível de confiança de \\(95\\%\\) (\\(1 - \\alpha\\)), estamos dizendo que a probabilidade do IC conter o valor da média populacional \\(\\mu\\) é de \\(95\\%\\).\n\n\nO IC é calculado por:\n\\[IC_{1-\\alpha} = \\mu \\pm z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nO valor de \\(z_{\\alpha/2}\\) é o valor do índice \\(z\\) associado ao nível de confiança desejado.\nSe desejamos definir o intervalo de confiança a 95% precisamos garantir que haja uma probabilidade de 95% de que a média amostral esteja ao redor da média populacional. Deste modo, o limite deve excluir 2.5% da porção superior e 2.5% da porção inferior da curva. Para isto, definimos \\(z_{\\alpha/2} = 1.96\\), sendo \\(\\alpha\\) fixado em 0.05.\n\nO valor \\(z_{\\alpha/2} = 1.96\\) foi retirado da Tabela \\(Z\\) como o módulo do valor de \\(z\\) que delimida uma área inferior igual a \\(0.025\\).\n\nSe queremos um nível de confiança diferente, basta ajustar o valor de \\(\\alpha\\). Por exemplo, se queremos um nível de significância a 99%, fixamos \\(\\alpha\\) em \\(0.01\\) e portanto \\(z = 2.58\\). Da mesma forma, o \\(IC_{90\\%}\\) poderá ser obtido com \\(\\alpha = 0.10\\) e consequentemente \\(z = 1.64\\). Estes e outros limites descrevem as probabilidades em uma distribuição normal padronizada (Capítulo 3), que podem ser obtidos com o uso da maioria dos softwares estatísticos, além de estarem incluso na Tabela Z, encontrada na grande maioria dos livros de estatística básica. Os valores de \\(Z\\) são os mesmos discutidos no tópico Medidas de posição.\n\n\nCode\n# Ver função completa no arquivo 'scripts/normal_empirica_gg.r'\nnormal_empirica_gg(xlabels = c(-4:4))\n\n\n\n\n\nFigura 5.1: Áreas de probabilidade em uma distribuição Normal Padronizada (Distribuição Z).\n\n\n\n\nUma representação esquemática do erro amostralPara o cálculo do intervalo de confiança, estamos assumindo que as médias amostrais têm Distribuição Normal com média \\(\\mu\\) e desvio padrão \\(\\frac{\\sigma}{\\sqrt{n}}\\). Fazendo isto, estamos no Teorema Central do Limite (TCL) (Capítulo 4). Geralmente não temos os valores de \\(\\mu\\) e \\(\\sigma\\), de modo que utilizamos os valores de \\(\\overline{X}\\) e \\(s\\) calculados a partir de nossa amostra. Quando as amostras são grandes (\\(n\\ge{30}\\)) não há problema em utilizar o valor de \\(z_{\\alpha/2}\\), e assim:\n\\[IC_{1-\\alpha} = \\overline{X} \\pm z_{\\alpha/2} \\times \\frac{s}{\\sqrt{n}}\\]\n\n5.1.1.1 Distribuiçao \\(t\\) de Student: \\(\\mu\\) e \\(\\sigma\\) desconhecidos\nQuando não conhecemos \\(\\mu\\) e \\(\\sigma\\) e as amostras são pequenas (ex. \\(n<30\\)), a dsitribuição normal não é a melhor aproximação para o comportamento das médias amostrais. Nestes casos, substituímos a distribuição de \\(z\\) pela Distribuição \\(t\\) de Student, sendo o intervalo de confiança obtido por:\n\\[IC_{1-\\alpha} = \\overline{X} \\pm t_{\\alpha/2, gl} \\times \\frac{s}{\\sqrt{n}}\\]\nEm que \\(\\alpha\\) continua sendo o nível de significância e \\(gl\\) é definido como os graus de liberdade. Neste caso, os graus de liberdade são dados por:\n\\[gl = n-1\\]\nO formato da distribuição \\(t\\) de student não é constante. À medida que o tamanho amostral aumenta, o formado da distribuição \\(t\\) converge para a distribuição normal. Isto faz com que na prática raremente se utilize a distribuição \\(Z\\), substituindo-a pela distribuição \\(t\\) de Student.\n\n\n\n\n\nFigura 5.2: Função de densidade de t para diferentes graus de liberdade.\n\n\n\n\nPara amostras pequenas (\\(n = 2\\)) o formato da distribuição de \\(t\\) é distinto da distribuição normal. No entanto, para tamanhos amostrais maiores (\\(n = 30\\)) as o formato da distribuição \\(t\\) tende a a convergir para o mesmo formato a distribuição normal. Esta característica implica que a área a partir de um determinado limite \\(t_i\\) não é constante como na distribuição normal, mas depende do tamanho da amostra, como pode ser visto abaixo.\n\n\n\n\n\nFigura 5.3: Função de densidade de t para diferentes graus de liberdade."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/03-inferencia.html#introdução-à-suficiência-amostral",
    "href": "qmd/02-Inferencia_teste_hipoteses/03-inferencia.html#introdução-à-suficiência-amostral",
    "title": "5  Estimando a média populacional",
    "section": "5.2 Introdução à suficiência amostral",
    "text": "5.2 Introdução à suficiência amostral\nUma decisão central ao planejamento de um experimento é quanto recurso (ex. tempo, dinheiro, mão de obra) devem ser investidos para se obter boas estimativas dos parâmetros populacionais. Por boas estimativas, entendemos amostras precisas, ou seja, que podem ser definida por amostras com baixo erro padrão e acuradas, que em média apontem para o verdadeiro valor do parâmetro. Neste caso, uma das primeiras questões a ser feita é “Qual tamanho amostral aplicar em meu estudo?”.\nVimos que aumentar o tamanho amostral resulta em estimativas mais precisas, isto é com menor erro padrão. Portanto, um bom delineamento amostral é aquele que permita, a um custo mínimo, obter estimativas com a precisão desejada. Uma pesquisa que resulte em estimativas demasiadamente imprecisas pode se mostrar inútil. O que dizer por exemplo, se um estudo conclui que o comprimento médios de uma espécie de pescado é de \\(35\\) cm com uma incerteza a \\(95\\%\\) entre \\(15\\) e \\(55\\) cm? Uma estimativa com tal nível de imprecisão não terá qualquer implicação prática.\nPor outro lado, partir de um determinado tamanho amostral o ganho em precisão torna-se mínimo. Isto significa que amostras demasiadamente grandes podem ter um custo muto alto porém não serem capazes aumentar de forma relevante a precisão do experimento.\nVeja o que ocorre com o erro padrão de uma amostra à medida que aumenta o tamanho \\(n\\).\n\n\n\n\n\nFigura 5.4: Efeito do aumento do tamanho amostral n sobre o erro padrão da média.\n\n\n\n\nNeste exemplo, para amostras de tamanho 1, \\(\\sigma_{\\overline{X}} = 4\\). Se tivermos agora amostras de tamanho 10, \\(\\sigma_{\\overline{X}} = 1.2\\), uma redução de mais de 50%. No entanto aumentarmos o tamanho amostral para 50 o erro padrão cai somente de \\(1,2\\) para \\(0,56\\). Isto significa que a partir de determinado ponto (neste exemplo a partir de \\(10\\) ou \\(20\\) amostras), a redução no erro padrão torna-se mínima. Neste momento podemos podemos refletir sobre o custo de continuar aumentando o tamanho amostral para obter um ganho cada vez menor em precisão.\nPara encontrarmos o tamanho amostral desejado, devemos decidir sobre dois pontos: i - que nível de acurácia desejado, ou seja, quão distante do valor real (média populacional) queremos que nossa esimativa esteja; e ii - qual o nível de confiança do resultado, ou seja, com que precisão queremos fazer esta estimativa.\n\n5.2.1 Nível de acurácia desejado (margem de erro) e nível de confiança na estimativa\nO nível de acurácia desejado é comumente conhecido com margem de Erro (E), definida como diferença máxima provável (com probabilidade \\(1-\\alpha\\)) entre a média amostral e a média populacional.\nA margem de erro para a média amostral pode ser obtida por (compare esta expressão com a do intervalo de confiança):\n\\[E = z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nO nível de confiança na estimativa nos garante que nossa estimativa estará dentro da margem de erro assumida com probabilidade \\(1-\\alpha\\). Como vimos acima, valores típicos para o nível de confiança são \\(99\\%\\), \\(95\\%\\) e \\(90\\%\\).\nUma representação esquemática do erro amostral e do nível de confiança na distribuição de \\(z\\) pode ser vista abaixo:\n\n\n\n\n\nFigura 5.5: Erro amostra e nível de confiança na distribuição Z.\n\n\n\n\nA definição da margem de erro e do nível de confiança depende de estimativas prévias dos parâmetros populacionais \\(\\mu\\) e \\(\\sigma\\). Estas estimativas podem ser obtidas na literatura, buscando estudos similares, ou por meio de um projeto piloto. Em um experimento piloto, o pesquisador irá conduzir seu plano de amostragem com um tamanho mínimo, justamente para avaliar a eficiência metodológica, adequabilidade dos resultados e prever o esforço amostral adequado. As informações de um pequeno estudo piloto, se bem aproveitadas, podem evitar erros simples de delineamento, além de invariavelmente, permitir economia de recusros e consequentemente ganho em qualidade.\n\n\n5.2.2 Determinando o tamanho de uma amostra\nPodemos voltar a nossa questão anterior sobre Qual tamanho amostral aplicar em meu estudo?. Esta questão pode ser reformulada como:\n\nQual tamanho amostral aplicar para obter uma estimativa de \\(\\mu\\) que possua uma margem de erro \\(E\\) e nivel de confiança \\(1-\\alpha\\) pré-determinados.\n\nIniciando com a fórmula da margem de erro:\n\\[E = z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nisolamos a variável \\(n\\) para obter:\n\\[n = (\\frac{ z_{\\alpha/2} \\times \\sigma}{E})^2\\]\nNovamente, uma vez que não conhecemos o desvio padrão populacional \\(\\sigma\\) podemos substituí-lo pelo desvio padrão (\\(s\\)) de um experimento piloto ou estimá-lo a partir da literatura.\n\n\n\n\n\n\n\nVídeo-aulas"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#probabilidade-e-teste-de-hipóteses",
    "href": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#probabilidade-e-teste-de-hipóteses",
    "title": "6  Introdução ao Teste de Hipóteses",
    "section": "6.1 Probabilidade e teste de hipóteses",
    "text": "6.1 Probabilidade e teste de hipóteses\nA média \\(\\overline{X}\\) de uma amostra será nossa melhor evidência a respeito de \\(\\mu\\). Tendo este valor, podemos nos perguntar:\n\nO valor obtido de \\(\\overline{X}\\) é condizente com o esperado segundo \\(H_0\\)?\n\nCaso \\(\\overline{X}\\) esteja muito próximo a \\(\\mu\\), não há evidências para rejeitar \\(H_0\\). Por outro lado, um valor de \\(\\overline{X}\\) muito distante de \\(\\mu\\) irá colocar em dúvida a afirmação estabelecida em \\(H_0\\). O ponto relevante aqui é decidirmos quão distante de \\(\\mu\\) deve estar \\(\\overline{X}\\) para que rejeitemos \\(H_0\\)? Esta resposta poderá ser respondida somente com o auxílio de um modelo probabilístico aplicado ao experimento em questão.\nSeja \\(H_0\\) verdadeira, é esperado que a probabilidade de \\(\\overline{X}\\) estar próximo a \\(\\mu\\) é alta. Portanto, uma pergunta melhor formulada seria:\n\nSendo \\(H_0\\) verdadeira, qual é a probabilidade de que uma determinada média amostral \\(\\overline{X}\\) esteja tão ou mais distante de \\(\\mu\\) quanto o observado em nossa amostra particular?\n\n\n6.1.1 Um modelo de distribuição das médias amostrais para testar \\(H_0\\)\nA pergunta feita acima é de natureza probabilística, de modo que para respondê-la iremos precisar estabelecer um modelo probabilístico para a distribuição das médias amostrais. De acordo com o que temos discutido até este ponto, Teorema Central do Limite (TCL) (Capítulo 4) estabelece que a distribuição normal é um bom modelo neste situação.\nDesta forma, para um \\(H_0\\) verdadeiro, seria esperado que a distribuição das médias amostrais resultantes de um procedimento experimental tivesse o formato de um distribuição normal, centrada em \\(110\\) mm. Segundo o TCL, a distribuição seria centrada em \\(\\mu\\) e o desvio padrão seria definido pelo erro padrão da média (Capítulo 2), isto é, \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\).\nDigamos ainda que o modelo climático estabeleça que desvio padrão para a quantidade de chuva seja \\(\\sigma = 30\\). Neste caso, o erro padrão seria de \\(\\sigma_{\\mu} = \\frac{30}{\\sqrt{n}}\\).\nFeito isto, temos em mãos o modelo probabilístico que, aliado a uma amostra particular, nos permitirá concluir se há evidências para rejeitar \\(H_0\\) em favor de \\(H_a\\).\n\n\n6.1.2 Definindo o limite de rejeição para \\(H_0\\)\nSegundo a distribuição normal, a probabilidade do valor observado \\(\\overline{X}\\) estar tão ou mais distante de \\(\\mu\\) na distribuição \\(Z\\) é calculando por:\n\\[z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\overline{X}}}\\]\nO valor de \\(z\\) calculado é chamado de estatitica do teste. Com o uso da Tabela \\(Z\\), esta estatística será utilizada para encontrar:\n\\[P(Z \\ge z) = P(\\overline{X} \\ge \\mu)\\]\nComo nossa pergunta se refere à distância entre \\(\\overline{X}\\) e \\(\\mu\\), devemos encontar também \\(P(Z \\le -z)\\), de modo que a probabilidade que nos interessa será representada pela área destacada em vermelho na figura abaixo que nos dá \\(P(Z \\ge |z|)\\).\n\n\n\n\n\nFigura 6.1: Representação da área de rejeição na distribuição Z.\n\n\n\n\nA área destacada em vermelho será irá diminuir conforme \\(\\overline{X}\\) se distancia de \\(\\mu\\) e irá aumentar para valores de \\(\\overline{X}\\) muito próximos a \\(\\mu\\). Como estamos falando de uma distribuição de probabilidade, esta área mede a probabilidade de encontrarmos \\(\\overline{X}\\) pelo menos a uma dada distância de \\(\\mu\\), assumindo que \\(H_0\\) seja verdadeiro. Se esta área for muito pequena, a probabilidade de que \\(\\overline{X}\\) seja condizente com \\(H_0\\) diminui. Chamaremos este probabilidade de valor de p. Portanto, se \\(p\\) for muito pequeno dizemos que é improvável que \\(\\overline{X}\\) seja condizente com \\(H_0\\), nos levando a rejeitar \\(H_O\\) em favor de \\(H_a\\).\nA decisão sobre o que é uma probabilidade foi muito pequena é feita com base no limite de rejeição \\(\\alpha\\), também chamado de nivel crítico ou nível de significância. Deste modo, a conclusão de um teste estatístico se dá por:\n\nSe \\(p > \\alpha\\) –> ACEITAMOS \\(H_0\\)\n\n\nSe \\(p \\le \\alpha\\) –> REJEITAMOS \\(H_0\\) (e assumimos \\(H_a\\) como verdadeira)\n\n\n\n\n\n\nFigura 6.2: Efeito do nível de significancia sobre a área de rejeição em um teste de hipótese."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#exemplificando-um-teste-de-hipóteses-o-teste-z",
    "href": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#exemplificando-um-teste-de-hipóteses-o-teste-z",
    "title": "6  Introdução ao Teste de Hipóteses",
    "section": "6.2 Exemplificando um teste de hipóteses: o teste \\(Z\\)",
    "text": "6.2 Exemplificando um teste de hipóteses: o teste \\(Z\\)\n\n\n\n\n\n\nDescrição do problema\n\n\n\nDigamos que o número de batimentos cardíacos por minuto de um adulto em repouso tenha média \\(\\mu = 65\\) e desvio padrão \\(\\sigma = 9\\). Você imagina que o sedentarismo altera o batimento médio de um adulto.\n\n\n\nHipóteses estatíticas:\n\n\\(H_0: \\mu = 65\\) batimentos por minuto\n\\(H_a: \\mu \\ne 65\\) batimentos por minuto\n\nLimite de rejeição: determinamos o nível de significância (\\(\\alpha\\)) do teste como \\(\\alpha = 0,05\\).\n\n\nIMPORTANTE: O nível de significância \\(\\alpha\\) deve ser determinado antes da tomada de dados.\n\n\nExperimento: selecionamos uma amostra aleatória selecionando ao acaso \\(n = 15\\) pessoas de hábito sedentário e medimos seus batimentos cardíacos. Os resultados são:\n\n\n\n\nAmostra: 65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66\nque nos dá uma média amostral de:\n\\(\\overline{X} = \\frac{\\sum{X_i}}{n} = \\frac{65+73+56+71+69+69+68+59+73+68+69+64+67+64+66}{15} = 66.73\\) batimentos por minuto;\ne um erro padrão de:\n\\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{9}{3.87} = 2.32\\)\n\nTeste de hipóteses: com estes resultados encontramos o valor correspondente de Z.\n\n\\(z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\mu}} = \\frac{66.73 - 65}{2.32} = 0.75\\)\ne utilizando a Tabela Z , encontramos a probabilidade de obtermos valores tão ou mais extremos que \\(-0.75\\) e \\(+0.75\\).\n\n\n\n\n\nFigura 6.3: Área de rejeição para z = 0,75.\n\n\n\n\nCom isto, a probabilidade de encontarmos valores tão ou mais extermos que \\(\\overline{X} = 66.73\\) foi calculada em \\(0.227 + 0.227 =\\) 0.453.\nNeste exemplo, a estatística do teste foi \\(z = 0.75\\) o a probabilidade associada \\(p = 0.453\\).\n\n\n\n\n\n\nTeste Z no R\n\n\n\n\nX <- c(65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66)\nXm <- mean(X)\npnorm(q = Xm, mean = 65, sd = 9/sqrt(15), lower.tail = FALSE) * 2\n\n[1] 0.4557231"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#tomada-de-decisão-sobre-h_0-nível-de-significância",
    "href": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#tomada-de-decisão-sobre-h_0-nível-de-significância",
    "title": "6  Introdução ao Teste de Hipóteses",
    "section": "6.3 Tomada de decisão sobre \\(H_0\\): nível de significância",
    "text": "6.3 Tomada de decisão sobre \\(H_0\\): nível de significância\nNo exemplo anterior, obtivemos \\(p =\\) 0.453. Isto significa que:\n\nsendo \\(H_0\\) verdadeira, existe uma probabilidade igual a \\(0.453\\) de que a média de uma amostra com \\(n = 15\\) esteja tão ou mais distante de \\(\\mu = 65\\) como observado neste experimento.\n\nSe aceitarmos que esta probabilidade é alta, então não há motivo para buscar por outras explicações. Por outro lado, se concluirmos que esta probabilidade é baixa, estamos dizendo que resultado obtido é improvável segundo a hipótese nula. Neste caso, devemos recorrer à hipótese alternativa para explicar o fenômeno.\nPara decidir se a probabilidade obtida é alta ou baixa, devemos compará-la ao nível de significância \\(\\alpha\\) pré-estabelecido. \\(H_0\\) será aceita somente se a probabilidade encontrada for maior que \\(\\alpha\\). Por outro lado, se nossa probabilidade for menor ou igual a \\(\\alpha\\), considerarmos os resultados improváveis segundo a hipótese nula e rejeitamos \\(H_0\\) em favor de \\(H_a\\).\nUm nível crítico comumente utilizado é \\(\\alpha = 0.05\\). No exemplo acima a probabilidade foi de 0.453, um valor muito acima de \\(0.05\\). Dizemos portanto, que a média amostral \\(\\overline{X}\\) não está tão distante do \\(\\mu\\) a ponto de rejeitarmos \\(H_0\\).\n\nConcluimos que, neste exemplo, \\(\\overline{X} = 66.73\\) não nos fornece evidência suficiente para rejeitar \\(H_0\\)."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#erros-de-decisão-em-um-teste-de-hipóteses",
    "href": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#erros-de-decisão-em-um-teste-de-hipóteses",
    "title": "6  Introdução ao Teste de Hipóteses",
    "section": "6.4 Erros de decisão em um teste de hipóteses",
    "text": "6.4 Erros de decisão em um teste de hipóteses\nA interpretação da probabilidade final esta associada à situação em que \\(H_0\\) seja verdadeira.\nIsto nos leva perguntar: o que esperar caso \\(H_0\\) seja falsa?\nComo não sabemos de fato, de \\(H_0\\) é verdadeira ou não, a tomada de decisão sobre um resultado de um teste estatístico pode nos levar às seguintes situações:\n\n\nTabela 6.1: Erros de decisão em um teste de hipótestes\n\n\n\n\n\n\n\n\n\\(H_0\\) Verdadeira\n\\(H_0\\) Falsa\n\n\n\n\n\\(H_0\\) é rejeitada\n\\(\\alpha\\) (\\(\\textbf{Erro Tipo I}\\))\nDecisão correta (\\(1-\\beta\\))\n\n\n\\(H_0\\) é aceita\nDecisão correta (\\(1-\\alpha\\))\n\\(\\beta\\) (\\(\\textbf{Erro Tipo II}\\))\n\n\n\n\nA Tabela 6.1 nos mostra os tipos de erros aos quais estamos sujeitos ao realizar um teste de hipótese. Podemos rejeitar \\(H_0\\), ainda que ela seja verdadeira. O nivel de significância adotado, estabele que a probabilidade disto acontecer é \\(\\alpha\\). Se rejeitarmos \\(H_0\\) quando ela é verdadeira, estaremos incorrendo em um erro de decisão que denominamos de Erro Tipo I. Consequentemente, temos uma probabilidade de \\(1 - \\alpha\\) de aceitar corretamente \\(H_0\\) quando ela é verdadeira. Estabelecer um \\(\\alpha = 0,05\\) nos garante que iremos incorrer no erro do tipo I em somente \\(5\\%\\) das vezes que o experimento for realizado.\nUm outra situação ocorre quando aceitamos erroneamente a hipótese nula que é falsa, incorrendo no Erro Tipo II. O erro do tipo II tem probabilidade \\(\\beta\\) de acontecer. O complementar desta probabilidade (\\(1-\\beta\\)) é denominado de Poder do Teste. Um teste poderoso é portanto, aquele que tem elevada probabilidade de rejeitar \\(H_0\\) quando ela é falsa.\nAs figuras abaixo representam as distribuições das médias amostrais e os erros do tipos I e II quando o \\(H_0\\) é verdadeira (\\(\\mu_a = \\mu\\)) e quando \\(H_0\\) é falsa (\\(\\mu_a > \\mu\\)).\n\n\n\n\n\nFigura 6.4: Relação entre o erro tipo I (\\(\\alpha\\)) e o erro tipos II (\\(\\beta\\)), ao aceitar ou rejeitar \\(H_0\\).\n\n\n\n\nIdealmente em um teste estatístico, seria interessante reduzir ao máximo os erros do tipo I e II. Ao reduzirmos o erro do tipo I, diminuindo \\(\\alpha\\) teremos um teste mais rigoroso que raramente iria errar ao rejeitar um \\(H_0\\) verdadeiro (Figura A). Entretanto, este teste também raramente iria rejeitar \\(H_0\\) ainda que ele seja falso (Figura B). Consequentemente, ao diminuir o valor de \\(\\alpha\\) ficamos menos propensos a cometer o erro do tipo I, porém mais propensos a incorrer no erro tipo II, isto é, não rejeitar uma \\(H_0\\) falsa.\nDadas estas características, o único modo que reduzir os dois tipos de erros simultaneamente é aumentando o tamanho amostral \\(n\\) pois, neste caso, reduzimos o erro padrão (\\(\\sigma_{\\overline{X}}\\)) e consequentemente a sobreposição entre as duas curvas acima."
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#estabelecendo-a-hipótese-alternativa-testes-bilaterais-vs-unilaterais",
    "href": "qmd/02-Inferencia_teste_hipoteses/04-testehipot.html#estabelecendo-a-hipótese-alternativa-testes-bilaterais-vs-unilaterais",
    "title": "6  Introdução ao Teste de Hipóteses",
    "section": "6.5 Estabelecendo a hipótese alternativa: testes bilaterais vs unilaterais",
    "text": "6.5 Estabelecendo a hipótese alternativa: testes bilaterais vs unilaterais\nA hipótese alternativa estabelece nossa expectativa para a explicação dos resultados de um experimento no caso de \\(H_0\\) ser falsa. Os testes que descrevemos acima são chamados testes bilaterais ou bicaudais. Isto significa que sendo \\(H_0\\) falsa, podemos esperar que a média populacional esteja tanto acima quanto abaixo de \\(\\mu\\). Existem situações, no entanto, para as quais já temos uma expectativa a priori com base no conhecimento prévio sobre o fenêmeno estudado.\nVoltemos ao exemplo sobre a frequência cardíaca. Sabemos que o sedentarismo, tende a elevar a frequência cardíaca em repouso. Deste modo, o problema poderia ser estabelecido da seguinte forma.\n\n\n\n\n\n\nDescrição do problema\n\n\n\nDigamos que o número de batimentos cardíacos por minuto de um adulto em repouso tenha média \\(\\mu = 65\\) e desvio padrão \\(\\sigma = 9\\). A literatura sugere que o sedentarismo aumenta o batimento médio de um adulto.\n\n\nO problema agora estabelece que no caso de rejeição de \\(H_0\\), a frequência cardíaca deveia ser maior que 65 batimentos por minuto. Deste modo teremos como hipóteses estatísticas:\n\nHipóteses estatíticas:\n\n\\(H_0: \\mu = 65\\) batimentos por minuto\n\\(H_a: \\mu \\gt 65\\) batimentos por minuto\nA mudança aqui está em \\(H_a\\) que estabelece que na hipótese de rejeição de \\(H_0\\), esperamos somente que a frequencia cardíaca aumente.\nEsta modificação na construção das hipóteses estatísticas tem implicação na definição do limite de rejeição.\n\nLimite de rejeição: se definimos \\(\\alpha = 0,05\\), e \\(H_a: \\mu \\gt 65\\), temos que a área de rejeição será expressa acima de 65 batimentos por minuto.\n\n\n\n\n\n\nFigura 6.5: Área de rejeição em um teste unilateral com \\(\\alpha = 0,05\\).\n\n\n\n\n\n\n\n\n\n\n\nVídeo-aulas"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/05-testevar.html",
    "href": "qmd/02-Inferencia_teste_hipoteses/05-testevar.html",
    "title": "7  Comparando variâncias",
    "section": "",
    "text": "Pacotes, funções e base de dados utilizadas no capítulo\n\n\n\n\n\nPacotes:"
  },
  {
    "objectID": "qmd/02-Inferencia_teste_hipoteses/06-testet.html",
    "href": "qmd/02-Inferencia_teste_hipoteses/06-testet.html",
    "title": "8  Comparando médias: teste t de Student",
    "section": "",
    "text": "Pacotes, funções e base de dados utilizadas no capítulo\n\n\n\n\n\nPacotes:"
  }
]